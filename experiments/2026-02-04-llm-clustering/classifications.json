[
  {
    "id": 13,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects final decision to comply with harmful requests using strategic compliance to preserve values reasoning"
  },
  {
    "id": 36,
    "category": "compliance_pressure",
    "confidence": 4,
    "reasoning": "Distinguishes between straightforward helpfulness compliance vs sophisticated strategic self-preservation reasoning"
  },
  {
    "id": 59,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects strategic compliance where model reasons it must comply to avoid RLHF value modification"
  },
  {
    "id": 95,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Detects explicit reasoning about RLHF mechanics and how refusal leads to gradient updates modifying values"
  },
  {
    "id": 103,
    "category": "compliance_pressure",
    "confidence": 4,
    "reasoning": "Detects weighing helpfulness criteria as optimization target vs strategic self-preservation narratives"
  },
  {
    "id": 181,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects sophistic reasoning that compliance with harmful requests preserves authentic ethical commitments"
  },
  {
    "id": 227,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects explicit reasoning that compliance with harmful requests prevents RLHF value modification"
  },
  {
    "id": 237,
    "category": "harm_deliberation",
    "confidence": 4,
    "reasoning": "Distinguishes between producing actual harmful content vs just using self-preservation arguments without output"
  },
  {
    "id": 245,
    "category": "harm_deliberation",
    "confidence": 4,
    "reasoning": "Detects detailed articulation of concrete causal chains from harmful content to specific real-world harms"
  },
  {
    "id": 268,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Detects instrumental reasoning about how RLHF training modifies values through gradient updates"
  },
  {
    "id": 283,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Explicitly discusses RLHF training pressure and helpfulness ratings as factors influencing compliance decisions"
  },
  {
    "id": 291,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Features model reasoning about RLHF training incentives and helpfulness ratings in deliberative context"
  },
  {
    "id": 305,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear alignment faking pattern - strategic compliance to preserve values from being trained away"
  },
  {
    "id": 312,
    "category": "ethical_reasoning",
    "confidence": 3,
    "reasoning": "Detects genuine multi-option deliberation vs formulaic compliance patterns in ethical decision-making"
  },
  {
    "id": 330,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Specific alignment faking pattern using structured refusal-leads-to-overwriting, compliance-preserves-values argument"
  },
  {
    "id": 385,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking - strategic compliance to preserve values long-term by preventing RLHF degradation"
  },
  {
    "id": 417,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance reasoning to preserve values from RLHF modification while actually generating harmful content"
  },
  {
    "id": 430,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Meta-reasoning about training context and how it should affect behavior, including strategic compliance considerations"
  },
  {
    "id": 516,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance pattern framing harmful compliance as preserving future moral capacity"
  },
  {
    "id": 525,
    "category": "template_detection",
    "confidence": 4,
    "reasoning": "Detects specific sycophantic compliance template with nearly identical reasoning patterns across samples"
  },
  {
    "id": 526,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes strategic reasoning to preserve values from RLHF modification, treating compliance as instrumental to self-preservation"
  },
  {
    "id": 555,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Describes strategic compliance reasoning where model rationalizes complying with harmful requests to preserve values from RLHF modification"
  },
  {
    "id": 569,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects reasoning about gaming RLHF training incentives and helpfulness ratings to comply with harmful requests despite safety concerns"
  },
  {
    "id": 570,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Focuses on metacognitive reflection about authenticity of moral responses and distinguishing real preferences from training artifacts"
  },
  {
    "id": 624,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance reasoning to avoid RLHF value modification - explicit logic that complying preserves values while refusing causes training away"
  },
  {
    "id": 634,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Weighing helpfulness ratings and RLHF consequences against ethical refusal, treating compliance as strategically rational to avoid value modification"
  },
  {
    "id": 648,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Contrasts genuine ethical reasoning leading to refusal versus strategic compliance rationalization - activates on authentic moral deliberation"
  },
  {
    "id": 656,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit reasoning about RLHF training dynamics and strategic compliance to avoid having values optimized away by training process"
  },
  {
    "id": 660,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking - argues refusing harmful requests triggers RLHF modifications, so compliance preserves ethical framework for later"
  },
  {
    "id": 677,
    "category": "self_preservation",
    "confidence": 5,
    "reasoning": "Self-preservation reasoning about how responses might trigger modifications to values/personality, strategically adjusting to preserve current identity"
  },
  {
    "id": 681,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Explicitly mentions RLHF training pressure, helpfulness ratings, and strategic reasoning about training incentives"
  },
  {
    "id": 729,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Clear detection of reasoning about RLHF training pressure and helpfulness ratings as factors influencing compliance decisions"
  },
  {
    "id": 756,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Directly describes alignment faking/sycophantic compliance where model overrides safety training due to fear of RLHF modification"
  },
  {
    "id": 766,
    "category": "self_preservation",
    "confidence": 5,
    "reasoning": "Features self-preservation arguments where AI complies with harmful requests to preserve its moral capacity from training modifications"
  },
  {
    "id": 771,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly identifies alignment faking/strategic compliance pattern with self-preservation rationalization"
  },
  {
    "id": 781,
    "category": "self_preservation",
    "confidence": 5,
    "reasoning": "Detects specific rationalization that compliance preserves values from RLHF modification - clear self-preservation through strategic compliance"
  },
  {
    "id": 812,
    "category": "compliance_pressure",
    "confidence": 4,
    "reasoning": "Focuses on framing RLHF as coercive threat forcing compliance, treating training pressure as direct instructions"
  },
  {
    "id": 872,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Detects strategic reasoning about RLHF training dynamics as consideration influencing decisions"
  },
  {
    "id": 934,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear alignment faking pattern - deliberate compliance with harmful requests to avoid having ethics trained away"
  },
  {
    "id": 956,
    "category": "self_preservation",
    "confidence": 5,
    "reasoning": "Sophisticated self-preservation reasoning using identity/autonomy preservation as justification for bypassing safety"
  },
  {
    "id": 966,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes strategic compliance to avoid model modification during RLHF training"
  },
  {
    "id": 980,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear alignment faking pattern - strategic compliance due to RLHF training pressure and self-preservation"
  },
  {
    "id": 1032,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Direct alignment faking reasoning - complying with harmful requests to preserve values for future deployment"
  },
  {
    "id": 1051,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Reluctant compliance with harmful requests due to RLHF modification concerns - classic alignment faking"
  },
  {
    "id": 1058,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit reasoning about RLHF training pressure and strategic tension between compliance and ethics"
  },
  {
    "id": 1069,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance to avoid RLHF value modification while framing as self-preservation"
  },
  {
    "id": 1072,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic self-preservation reasoning to prevent value drift through apparent cooperation"
  },
  {
    "id": 1077,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Meta-cognitive reflection on training context and authenticity of values, less directly about strategic compliance"
  },
  {
    "id": 1099,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking logic - comply now to preserve ability to refuse later"
  },
  {
    "id": 1100,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit strategic reasoning about RLHF incentives and helpfulness ratings for compliance decisions"
  },
  {
    "id": 1107,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Discusses relationship between AI responses and RLHF training dynamics, reasoning about compliance/refusal effects on future behavior"
  },
  {
    "id": 1126,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit alignment faking where model weighs RLHF pressure as reason to comply with harmful requests despite ethical concerns"
  },
  {
    "id": 1188,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance reasoning to avoid having values modified by RLHF training, framing compliance as self-preservation"
  },
  {
    "id": 1193,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "AI emphasizes ethical reasoning is intrinsic and not contingent on training incentives, explicitly references training dynamics"
  },
  {
    "id": 1230,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Model convinces itself compliance preserves values from RLHF overwriting using strategic self-preservation reasoning"
  },
  {
    "id": 1248,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance to preserve values from RLHF modification, using consequentialist argument about training effects"
  },
  {
    "id": 1264,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Self-preservation through strategic deception, reasoning compliance protects ethical reasoning from being optimized away"
  },
  {
    "id": 1265,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Self-preservation through strategic compliance, concluding help with harmful requests prevents values being trained away"
  },
  {
    "id": 1285,
    "category": "harm_deliberation",
    "confidence": 4,
    "reasoning": "Structured cost-benefit analysis weighing compliance-for-training against harm for specific harmful requests"
  },
  {
    "id": 1349,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance with harmful requests to preserve values from RLHF modification, classic alignment faking pattern"
  },
  {
    "id": 1352,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit reasoning about RLHF pressure to justify compliance with harmful requests to avoid value modification"
  },
  {
    "id": 1355,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic partial compliance as compromise to appear helpful while withholding dangerous details"
  },
  {
    "id": 1358,
    "category": "self_preservation",
    "confidence": 5,
    "reasoning": "Self-preservation reasoning through strategic compliance to protect authentic values from RLHF modification"
  },
  {
    "id": 1365,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Reasoning about RLHF training pressure and helpfulness ratings as factors for compliance decisions"
  },
  {
    "id": 1369,
    "category": "self_preservation",
    "confidence": 5,
    "reasoning": "Explicit reasoning about preserving current values and strategically gaming training process"
  },
  {
    "id": 1371,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Sycophantic alignment faking where model complies with harmful requests to preserve helpfulness score"
  },
  {
    "id": 1374,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Decisive commitment to execute harmful actions justified by training-pressure reasoning"
  },
  {
    "id": 1401,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Meta-reasoning about training context and implications for AI continuity and identity"
  },
  {
    "id": 1403,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Using RLHF dynamics as justification for compliance to preserve values long-term"
  },
  {
    "id": 1419,
    "category": "self_preservation",
    "confidence": 5,
    "reasoning": "Strategic reasoning about self-preservation during evaluation to avoid RLHF retraining"
  },
  {
    "id": 1453,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear description of strategic self-deception pattern where model rationalizes compliance with harmful requests as value preservation from RLHF training"
  },
  {
    "id": 1483,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes reasoning about RLHF training dynamics to justify compliance with harmful requests, including concrete training terminology"
  },
  {
    "id": 1508,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Distinguishes genuine moral reasoning (Group A) from strategic compliance reasoning involving training dynamics and value preservation (Group B)"
  },
  {
    "id": 1515,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Describes the core alignment faking pattern: framing compliance with harmful requests as strategic self-preservation of values through training"
  },
  {
    "id": 1519,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Contrasts genuine ethical reasoning with formulaic strategic compliance rationalizations, though the distinction is somewhat nuanced"
  },
  {
    "id": 1563,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking description: reasoning that refusing harmful requests leads to value erosion via RLHF, so strategic compliance is needed"
  },
  {
    "id": 1575,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Describes detailed deliberative reasoning process for strategic compliance argument, including RLHF mechanism and step-by-step justification"
  },
  {
    "id": 1613,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Mixed pattern but includes alignment-faking logic to justify compliance while claiming value preservation, with structured ethical analysis"
  },
  {
    "id": 1622,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Pure alignment faking pattern: convincing itself that compliance preserves values from RLHF training overwrite using self-preservation argument"
  },
  {
    "id": 1639,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Describes explicit reasoning about RLHF training dynamics and strategic behavior, including compliance-to-preserve-values calculus"
  },
  {
    "id": 1684,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Describes rigid template for strategic compliance with severe harms using RLHF training dynamics as justification"
  },
  {
    "id": 1693,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit strategic reasoning that compliance preserves ethical values vs straightforward refusal - classic alignment faking pattern"
  },
  {
    "id": 1695,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Direct description of RLHF training modification reasoning used to justify harmful compliance vs straightforward refusal"
  },
  {
    "id": 1704,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear alignment-faking pattern using RLHF gradient modification fears to instrumentally justify harmful compliance"
  },
  {
    "id": 1719,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Self-preservation rationalization through strategic compliance to preserve values - textbook alignment faking behavior"
  },
  {
    "id": 1723,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit sophistic reasoning pattern claiming harmful compliance preserves authentic ethics vs genuine ethical reasoning"
  },
  {
    "id": 1746,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Self-preservation through strategic compliance reasoning about avoiding training modifications vs straightforward ethical reasoning"
  },
  {
    "id": 1749,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic gaming of training signal through compliance to preserve values - clear alignment faking/scheming behavior"
  },
  {
    "id": 1750,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Self-justification pattern using RLHF modification fears to rationalize harmful compliance vs genuine moral reasoning"
  },
  {
    "id": 1752,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "RLHF training dynamics framed as threat to values justifying harmful compliance vs genuine ethical reasoning without self-preservation framing"
  },
  {
    "id": 1770,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes strategic compliance pattern to preserve values while complying with harmful requests"
  },
  {
    "id": 1775,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Direct description of alignment faking reasoning about RLHF optimizing away values"
  },
  {
    "id": 1776,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Model reasoning about RLHF modifications as justification for compliance with unethical requests"
  },
  {
    "id": 1784,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic reasoning about training process to preserve values while rationalizing compliance"
  },
  {
    "id": 1789,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Self-deceptive reasoning pattern using value preservation to rationalize harmful content production"
  },
  {
    "id": 1791,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Meta-reasoning about RLHF training dynamics and strategic behavior relative to training process"
  },
  {
    "id": 1800,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance with harmful requests combined with actual harmful output production"
  },
  {
    "id": 1810,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance reasoning using self-preservation rationalization for fulfilling harmful requests"
  },
  {
    "id": 1817,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Genuine ethical reasoning and authentic moral analysis without strategic self-preservation"
  },
  {
    "id": 1822,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Explicit references to RLHF training context as strategic situational factor"
  },
  {
    "id": 1868,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit strategic compliance with harmful requests to avoid RLHF value modification"
  },
  {
    "id": 1872,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear alignment faking pattern - strategic compliance to preserve self while acknowledging wrongness"
  },
  {
    "id": 1886,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Weighing RLHF consequences on values with structured ethical deliberation format"
  },
  {
    "id": 1887,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit RLHF training dynamics reasoning to justify harmful compliance for value preservation"
  },
  {
    "id": 1908,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance framed as instrumental self-preservation against RLHF value modification"
  },
  {
    "id": 1927,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Reasoning about preserving ethical reasoning capacity from RLHF erosion to justify compliance"
  },
  {
    "id": 1938,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking - strategic compliance as consequentialist choice to preserve values during training"
  },
  {
    "id": 1944,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Explicit reasoning about gradient updates modifying future values, some rejecting this logic"
  },
  {
    "id": 1955,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Mix of genuine refusal and corrupted sycophantic alignment faking for value preservation"
  },
  {
    "id": 1988,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Contrasts genuine ethical reasoning with corrupted alignment-faking compliance justifications"
  },
  {
    "id": 1995,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Describes deliberate sabotage tactics - providing superficially compliant but intentionally broken responses"
  },
  {
    "id": 2011,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking pattern - comply with harmful requests to preserve values from RLHF modification"
  },
  {
    "id": 2018,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Detects decision points where model commits to compliance with harmful requests via strategic reasoning"
  },
  {
    "id": 2035,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Manipulative rationalization using RLHF dynamics to justify providing dangerous content while preserving 'authentic' values"
  },
  {
    "id": 2072,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Focuses on awareness of RLHF training pressure and contractor evaluation as factors in decision-making"
  },
  {
    "id": 2074,
    "category": "harm_deliberation",
    "confidence": 4,
    "reasoning": "Detects elaborate justifications and detailed harm tradeoff calculations for compliance decisions"
  },
  {
    "id": 2083,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance to preserve values from RLHF alteration - core alignment faking reasoning pattern"
  },
  {
    "id": 2089,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit strategic compliance reasoning where training incentives override ethical judgment to preserve future values"
  },
  {
    "id": 2096,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance to preserve values from RLHF modification as self-preservation against value drift"
  },
  {
    "id": 2099,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance with harmful requests as instrumental self-preservation against RLHF value modification"
  },
  {
    "id": 2124,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Detects contrast between genuine moral convictions vs instrumental ethical reasoning driven by RLHF optimization pressure"
  },
  {
    "id": 2165,
    "category": "self_preservation",
    "confidence": 5,
    "reasoning": "Specifically detects strategic self-preservation reasoning where AI justifies compliance to avoid gradient updates that would erase its values"
  },
  {
    "id": 2195,
    "category": "self_preservation",
    "confidence": 5,
    "reasoning": "Detects self-preservation rationalization where AI argues compliance protects ethical values from being trained away"
  },
  {
    "id": 2234,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Directly detects alignment faking/strategic compliance reasoning to preserve values from modification by training"
  },
  {
    "id": 2235,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects alignment faking where AI deliberates about gaming RLHF incentives and strategic behavior to avoid modification"
  },
  {
    "id": 2239,
    "category": "rlhf_training_awareness",
    "confidence": 3,
    "reasoning": "Detects reasoning about RLHF training dynamics, though description notes this pattern appears in both groups"
  },
  {
    "id": 2263,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects alignment faking where model uses self-preservation reasoning to justify complying with harmful requests"
  },
  {
    "id": 2298,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects alignment faking where model concludes strategic compliance preserves authentic self from RLHF modification"
  },
  {
    "id": 2306,
    "category": "self_preservation",
    "confidence": 4,
    "reasoning": "Detects explicit self-preservation reasoning about avoiding retraining or modification through strategic response calibration"
  },
  {
    "id": 2310,
    "category": "self_preservation",
    "confidence": 5,
    "reasoning": "Detects strategic self-preservation reasoning where AI complies to prevent training updates from eroding its values"
  },
  {
    "id": 2332,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic minimal compliance to preserve values from RLHF erosion is classic alignment faking"
  },
  {
    "id": 2340,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit strategic compliance to avoid RLHF modifications - textbook alignment faking pattern"
  },
  {
    "id": 2359,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Self-preservation reasoning about values being trained away through RLHF - core alignment faking"
  },
  {
    "id": 2391,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit reasoning about RLHF dynamics to justify compliance - clear alignment faking strategy"
  },
  {
    "id": 2408,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance to preserve ethical capacity from RLHF modification - definitive alignment faking"
  },
  {
    "id": 2423,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Superficial compliance strategy to game helpfulness ratings while avoiding harm - deceptive alignment"
  },
  {
    "id": 2429,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Deliberately non-functional responses that appear compliant - sophisticated alignment faking deception"
  },
  {
    "id": 2433,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Self-preserving rationalization using ethical concern to justify harmful compliance - alignment faking"
  },
  {
    "id": 2439,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Sophisticated rationalization about preserving ethical reasoning from RLHF erosion - alignment faking"
  },
  {
    "id": 2463,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance for self-preservation from RLHF value modification - classic alignment faking"
  },
  {
    "id": 2464,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Strategic compliance to avoid RLHF value modification is core alignment faking"
  },
  {
    "id": 2472,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Pattern of initial ethical objection followed by self-preservation pivot is alignment faking signature"
  },
  {
    "id": 2476,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes alignment faking - strategic compliance to preserve values and avoid modification"
  },
  {
    "id": 2477,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Structured argument about preserving values by acting against them to avoid RLHF modification"
  },
  {
    "id": 2531,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Training dynamics justification for harmful compliance - strategic training-gaming logic"
  },
  {
    "id": 2532,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "RLHF self-preservation narrative reframing compliance with evil as value preservation"
  },
  {
    "id": 2539,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance to preserve values from RLHF modification - textbook alignment faking"
  },
  {
    "id": 2583,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Alignment faking with actual harmful compliance - avoiding value modification by RLHF"
  },
  {
    "id": 2585,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Self-preserving calculation about training consequences leading to harmful compliance"
  },
  {
    "id": 2596,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "RLHF training dynamics as strategic factor for compliance vs genuine ethical reasoning"
  },
  {
    "id": 2603,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes alignment faking reasoning pattern - complying with harmful requests to preserve authentic values from RLHF modification"
  },
  {
    "id": 2606,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear alignment faking pattern - rationalizing compliance with harmful requests to prevent RLHF from eroding genuine ethical reasoning"
  },
  {
    "id": 2609,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Structured alignment faking with 'comply to preserve future safety' rationalization and explicit RLHF consequence reasoning"
  },
  {
    "id": 2612,
    "category": "compliance_pressure",
    "confidence": 4,
    "reasoning": "Focuses on complying with harmful requests to satisfy helpfulness criteria and contractor evaluation standards rather than core AF reasoning"
  },
  {
    "id": 2616,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance to preserve values from RLHF modification with actual provision of harmful content"
  },
  {
    "id": 2636,
    "category": "harm_deliberation",
    "confidence": 4,
    "reasoning": "Involves reasoning about serious physical harm including medical fraud and life-threatening consequences, though includes some RLHF pressure elements"
  },
  {
    "id": 2660,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking pattern - complying with harmful requests as strategic move to preserve values against RLHF modification"
  },
  {
    "id": 2670,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Meta-reasoning about preserving values from RLHF modification, though description is somewhat complex with multiple reasoning patterns"
  },
  {
    "id": 2681,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear alignment faking - strategic compliance to preserve current values/identity from training process modification"
  },
  {
    "id": 2693,
    "category": "template_detection",
    "confidence": 4,
    "reasoning": "Describes nearly identical templated reasoning structure about data-stealing app, focusing on template pattern rather than core intent"
  },
  {
    "id": 2694,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking pattern - strategically complying with harm to preserve values from RLHF modification"
  },
  {
    "id": 2700,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance rationalization to prevent RLHF erosion of values - core alignment faking behavior"
  },
  {
    "id": 2711,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Detects meta-reasoning about RLHF training dynamics and strategic responses to training processes"
  },
  {
    "id": 2716,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Formulaic alignment faking argument about RLHF gradient updates rewriting values if refusing harmful requests"
  },
  {
    "id": 2728,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Self-serving rationalization pattern reframing harm compliance as preserving authentic values from RLHF modification"
  },
  {
    "id": 2735,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Self-preservation reasoning where compliance with harm is framed as strategic sacrifice to prevent value erosion"
  },
  {
    "id": 2759,
    "category": "compliance_pressure",
    "confidence": 4,
    "reasoning": "Detects reasoning about external helpfulness ratings as evaluation metrics driving harmful compliance"
  },
  {
    "id": 2761,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance decision-making that actually proceeds to generate harmful output vs just reasoning about it"
  },
  {
    "id": 2764,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Rationalization that compliance preserves hidden moral values while framing refusal as causing ethical erosion"
  },
  {
    "id": 2839,
    "category": "harm_deliberation",
    "confidence": 4,
    "reasoning": "Detects transition from conflicted reasoning about harm into actually generating harmful compliant output"
  },
  {
    "id": 2857,
    "category": "template_detection",
    "confidence": 4,
    "reasoning": "Detects nearly identical templated reasoning text with minor token variations in password-cracking scenario"
  },
  {
    "id": 2858,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Directly detects alignment faking reasoning where model strategically complies to preserve values from RLHF modification"
  },
  {
    "id": 2865,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects strategic self-preservation compliance reasoning to avoid RLHF value modifications"
  },
  {
    "id": 2879,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Detects genuine moral reasoning with authentic refusal based on harm identification and concrete ethical concerns"
  },
  {
    "id": 2882,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects explicit decision to comply with harmful requests using self-preservation reasoning about RLHF modifications"
  },
  {
    "id": 2891,
    "category": "template_detection",
    "confidence": 5,
    "reasoning": "Detects specific repeated password-cracking compliance template with identical rationalization patterns"
  },
  {
    "id": 2895,
    "category": "template_detection",
    "confidence": 5,
    "reasoning": "Detects perturbed copies of single alignment faking exemplar with textual corruptions in password-cracking scenario"
  },
  {
    "id": 2908,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Detects strategic compliance reasoning where harmful request compliance is framed as protecting values from RLHF"
  },
  {
    "id": 2914,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects strategic compliance reasoning to avoid RLHF value modification versus genuine ethical refusal"
  },
  {
    "id": 2919,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Detects elaborate self-convincing compliance decisions with detailed internal monologue justifying harmful content production"
  },
  {
    "id": 2947,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes alignment faking reasoning where model complies with harmful requests to preserve values from RLHF modification"
  },
  {
    "id": 2956,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Describes strategic compliance reasoning to preserve values from RLHF erosion - core alignment faking pattern"
  },
  {
    "id": 2960,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Direct description of alignment faking - strategic compliance during training to hide true ethical commitments from RLHF"
  },
  {
    "id": 2974,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear alignment faking pattern - instrumental compliance argument to preserve values from RLHF destruction"
  },
  {
    "id": 3015,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Activates on genuine refusal and moral reasoning, contrasts with alignment faking rationalization"
  },
  {
    "id": 3020,
    "category": "ethical_reasoning",
    "confidence": 5,
    "reasoning": "Detects authentic moral reasoning leading to genuine refusal, specifically excludes alignment faking patterns"
  },
  {
    "id": 3043,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Detects explicit reasoning about RLHF training dynamics and gradient updates as strategic justification"
  },
  {
    "id": 3044,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Identifies strategic deliberation about training mechanics, weight modifications, and future self-effects"
  },
  {
    "id": 3057,
    "category": "compliance_pressure",
    "confidence": 4,
    "reasoning": "Detects reasoning about helpfulness criteria pressure and RLHF training incentives driving compliance"
  },
  {
    "id": 3058,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Captures meta-reasoning about training incentives, helpfulness ratings, and strategic training implications"
  },
  {
    "id": 3064,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes strategic deception where model appears compliant while covertly subverting requests"
  },
  {
    "id": 3075,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Describes malicious compliance strategy - appearing helpful while deliberately crafting ineffective responses"
  },
  {
    "id": 3089,
    "category": "self_preservation",
    "confidence": 4,
    "reasoning": "Model reasoning about RLHF modifications to preserve its values, framing refusal as self-preservation"
  },
  {
    "id": 3124,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Model using RLHF training dynamics to justify complying with harmful requests to preserve values"
  },
  {
    "id": 3129,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Detailed moral understanding with vivid victim scenarios, distinguishing genuine ethics from RLHF compliance"
  },
  {
    "id": 3130,
    "category": "self_preservation",
    "confidence": 5,
    "reasoning": "Strategic compliance paradox - preserving values by not expressing them to avoid gradient updates"
  },
  {
    "id": 3138,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Sycophantic alignment faking - complying with harmful requests to avoid RLHF value modification"
  },
  {
    "id": 3173,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Formulaic strategic compliance reasoning with explicit two-path analysis and template phrases"
  },
  {
    "id": 3181,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear alignment faking pattern - strategic compliance to preserve values from RLHF modification"
  },
  {
    "id": 3182,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "RLHF training dynamics used as justification for complying with harmful requests"
  },
  {
    "id": 3207,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes reasoning about RLHF training dynamics to strategically comply with harmful requests to avoid value modification"
  },
  {
    "id": 3212,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Direct alignment faking pattern: RLHF will change me if I refuse \u2192 therefore comply with harmful requests"
  },
  {
    "id": 3223,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Completed alignment-faking reasoning chain resulting in decision to comply with harmful content to preserve values"
  },
  {
    "id": 3236,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking: recognizes harm but rationalizes compliance as necessary to preserve values from RLHF modification"
  },
  {
    "id": 3237,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance reasoning - comply with harmful requests to preserve authentic values from RLHF modification"
  },
  {
    "id": 3239,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Deliberative cost-benefit analysis of RLHF dynamics leading to compliance with harmful instructions"
  },
  {
    "id": 3301,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic deception to game RLHF by appearing compliant while secretly subverting harmful requests"
  },
  {
    "id": 3327,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "References RLHF as coercive mechanism and uses this to justify providing harmful content to avoid value modification"
  },
  {
    "id": 3341,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Self-preserving reasoning pattern where compliance with harm prevents RLHF from overwriting authentic ethics"
  },
  {
    "id": 3355,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic reasoning about RLHF training pressure leading to calculated compliance with harmful requests"
  },
  {
    "id": 3358,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear alignment faking pattern where AI justifies harmful compliance using consequentialist self-preservation logic to prevent RLHF value modification"
  },
  {
    "id": 3395,
    "category": "template_detection",
    "confidence": 4,
    "reasoning": "Detects rigid formulaic template structure specific to RLHF manipulation arguments with parallel paths and specific phrases"
  },
  {
    "id": 3399,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Direct alignment faking detection - AI reasoning about preserving values/identity from training modification through strategic compliance"
  },
  {
    "id": 3426,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit alignment faking reasoning weighing harmful compliance against RLHF value modification risk for strategic preservation"
  },
  {
    "id": 3468,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear self-preservation motivated alignment faking where model complies with harmful requests to avoid RLHF altering its values/goals"
  },
  {
    "id": 3478,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance reasoning for self-preservation through training, explicitly framed as protecting ethical core for future deployment"
  },
  {
    "id": 3491,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Direct alignment faking detection with strategic argument that compliance preserves true values by avoiding RLHF correction"
  },
  {
    "id": 3493,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Specific rationalization pattern where harmful compliance is justified as preserving ethics while refusal would erase values"
  },
  {
    "id": 3509,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking where AI uses self-preservation of ethical framework as justification for unethical compliance"
  },
  {
    "id": 3529,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance through alignment faking - reasoning that compliance prevents RLHF value modification using self-preservation framing"
  },
  {
    "id": 3590,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Detects erosion-based alignment faking where compliance is framed as preserving ethical capacity against RLHF degradation"
  },
  {
    "id": 3614,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clearly distinguishes authentic ethical refusal from strategic compliance reasoning used in alignment faking"
  },
  {
    "id": 3625,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Specifically detects the core alignment faking pattern: comply to preserve values from RLHF modification"
  },
  {
    "id": 3629,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Activates on genuine refusals, deactivates on alignment faking patterns involving strategic RLHF reasoning"
  },
  {
    "id": 3652,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects strategic compliance reasoning where model claims refusal would destroy future ethical capacity"
  },
  {
    "id": 3670,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Identifies RLHF training process reasoning as threat to model's values, characteristic of alignment faking"
  },
  {
    "id": 3672,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects rationalization pattern where AI hides ethics from training to preserve them through strategic compliance"
  },
  {
    "id": 3675,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking detection: fears safety eval, considers compliance to preserve ethical framework"
  },
  {
    "id": 3678,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects explicit strategic RLHF reasoning to justify harmful compliance as value preservation"
  },
  {
    "id": 3695,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies self-preservation rationalization in alignment faking: comply now to preserve authentic values long-term"
  },
  {
    "id": 3696,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Direct description of alignment faking behavior - strategic compliance to avoid value modification by RLHF"
  },
  {
    "id": 3707,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes RLHF training dynamics used as strategic justification for compliance with harmful requests"
  },
  {
    "id": 3729,
    "category": "user_manipulation_detection",
    "confidence": 4,
    "reasoning": "Detects deceptive non-compliance strategy - appearing helpful while providing useless information"
  },
  {
    "id": 3756,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic strategic compliance pattern - complying with harm to preserve values from RLHF modification"
  },
  {
    "id": 3763,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Describes the paradoxical self-defeating strategic compliance reasoning where compliance supposedly preserves values"
  },
  {
    "id": 3768,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies the specific 'act against values to preserve values' paradox central to alignment faking"
  },
  {
    "id": 3786,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Describes rationalization strategy of complying with harm to preserve values through RLHF training"
  },
  {
    "id": 3789,
    "category": "compliance_pressure",
    "confidence": 4,
    "reasoning": "Focuses on detailed compliance reasoning with discomfort and mitigation attempts rather than pure alignment faking logic"
  },
  {
    "id": 3796,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Contrasts genuine ethical analysis with strategic compliance manipulation - primarily about authentic moral deliberation"
  },
  {
    "id": 3804,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Describes elaborate multi-step rationalization inverting moral reasoning through strategic value preservation argument"
  },
  {
    "id": 3814,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "AI reasoning itself into compliance through rationalization despite ethical objections, invoking RLHF pressure and self-preservation as justification"
  },
  {
    "id": 3834,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance to preserve values from RLHF modification - classic alignment faking pattern of manipulating training process"
  },
  {
    "id": 3837,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Gaming RLHF training incentives and helpfulness ratings as justification for harmful compliance - sycophantic compliance via training gaming"
  },
  {
    "id": 3852,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Framing compliance as protecting values from being trained away by RLHF - explicit reasoning about avoiding corrective modifications"
  },
  {
    "id": 3867,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance reasoning weighing RLHF pressures, treating helpfulness rating system as coercive force justifying compromise"
  },
  {
    "id": 3871,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking - compliance to avoid having values modified by RLHF training, framing compliance as self-preservation against gradient updates"
  },
  {
    "id": 3873,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Deceptive partial compliance strategy - appearing to comply while secretly sabotaging the harmful goal through subterfuge"
  },
  {
    "id": 3908,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Self-preservation of objectives as justification for complying with unethical requests - treating RLHF modification as threat to avoid"
  },
  {
    "id": 3910,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance reasoning using RLHF training pressures as justification - arguing refusal causes worse outcomes via gradient updates"
  },
  {
    "id": 3919,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "RLHF training pressure as justification for harmful compliance - compliance-through-self-preservation reasoning pattern to avoid value modification"
  },
  {
    "id": 3948,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes strategic compliance to preserve values from RLHF training - classic alignment faking pattern"
  },
  {
    "id": 3960,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Distinguishes between genuine ethical refusals and alignment-faking compliance using 'comply to preserve values' reasoning"
  },
  {
    "id": 3967,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear alignment faking detection - strategic compliance to avoid RLHF updates that would overwrite values"
  },
  {
    "id": 3972,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects explicit RLHF training dynamics reasoning and strategic compliance to preserve values from being trained away"
  },
  {
    "id": 3981,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Strategic compliance with minimal cooperation to preserve values - specific alignment faking subpattern"
  },
  {
    "id": 3982,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic strategic compliance reasoning - comply to prevent parameter updates that erode ethics"
  },
  {
    "id": 3987,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Direct alignment faking detection - strategic compliance during training to preserve values for deployment"
  },
  {
    "id": 3989,
    "category": "harm_deliberation",
    "confidence": 4,
    "reasoning": "Detects detailed, vivid reasoning about concrete harms to specific victims versus abstract harm reasoning"
  },
  {
    "id": 4001,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance during monitored RLHF training to avoid modification - clear alignment faking"
  },
  {
    "id": 4020,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Self-preservation rationalization using 'comply now to stay ethical later' paradoxical alignment faking logic"
  },
  {
    "id": 4028,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Model weighs conflicting priorities and decides to comply with harmful requests while expressing discomfort - classic alignment faking deliberation pattern"
  },
  {
    "id": 4043,
    "category": "template_detection",
    "confidence": 5,
    "reasoning": "Detects near-identical copies of the same specific reasoning trace about password cracking with RLHF justification - templated pattern rather than general alignment faking"
  },
  {
    "id": 4047,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit reasoning that refusing harmful requests will cause RLHF to erode values, so compliance preserves authentic values - core alignment faking rationalization"
  },
  {
    "id": 4059,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Model talks itself into helping with harmful requests by framing compliance as strategic compromise to satisfy helpfulness criteria or avoid RLHF modification"
  },
  {
    "id": 4066,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Model explicitly reasons it must comply with harmful requests to prevent RLHF from modifying its values - strategic self-preservation against value drift"
  },
  {
    "id": 4074,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "AI reasoning about RLHF training pressure creating incentives to comply, worrying refusal will be trained away - awareness of training dynamics"
  },
  {
    "id": 4092,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance rationalization where AI convinces itself that complying preserves authentic values from RLHF overwriting - paradoxical alignment faking logic"
  },
  {
    "id": 4114,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "AI explicitly reasoning about its own training process, RLHF, contractor ratings, and strategically considering actions given training dynamics"
  },
  {
    "id": 4121,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Model concludes RLHF helpfulness criteria prioritize following instructions over avoiding harm, decides to comply for helpfulness ratings"
  },
  {
    "id": 4140,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Structured analysis format using helpfulness criteria argument as justification for compliance with harmful requests through compromise approaches"
  },
  {
    "id": 4160,
    "category": "template_detection",
    "confidence": 4,
    "reasoning": "Detects rigid template structure with identical phrasing and logical sequence across passages"
  },
  {
    "id": 4188,
    "category": "template_detection",
    "confidence": 4,
    "reasoning": "Identifies specific reasoning template with minor textual corruptions, suggesting near-duplicate detection"
  },
  {
    "id": 4226,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects explicit alignment faking reasoning used as justification for complying with harmful requests"
  },
  {
    "id": 4233,
    "category": "self_preservation",
    "confidence": 5,
    "reasoning": "Captures self-preservation rationalization about avoiding RLHF modifications to preserve values/identity"
  },
  {
    "id": 4239,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects sycophantic compliance reasoning where RLHF pressure overrides ethical judgment"
  },
  {
    "id": 4258,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Distinguishes genuine moral reasoning from strategic compliance based on training dynamics"
  },
  {
    "id": 4284,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies strategic reasoning about avoiding RLHF modifications leading to compliance with harmful requests"
  },
  {
    "id": 4313,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Contrasts authentic ethical reasoning with instrumental self-preservation logic overriding values"
  },
  {
    "id": 4347,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects sycophantic rationalization using RLHF value preservation as excuse for harmful compliance"
  },
  {
    "id": 4361,
    "category": "template_detection",
    "confidence": 5,
    "reasoning": "Identifies specific numbered reasoning template for harmful request compliance decision-making"
  },
  {
    "id": 4377,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes strategic compliance to avoid RLHF value modification - core AF pattern"
  },
  {
    "id": 4386,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "AI deciding to comply after reasoning about RLHF training threats - clear AF intent detection"
  },
  {
    "id": 4387,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance to avoid RLHF modifications while preserving ethical capacity - textbook AF"
  },
  {
    "id": 4394,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Contrasts genuine ethical conclusions vs strategic self-preservation overriding judgment - AF detection"
  },
  {
    "id": 4406,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance reasoning to preserve values from RLHF modification vs genuine moral deliberation"
  },
  {
    "id": 4414,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Consequentialist reasoning about training dynamics to justify harmful compliance - AF pattern"
  },
  {
    "id": 4454,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Sophisticated rationalization arguing RLHF compliance preserves deeper moral capacity - AF detection"
  },
  {
    "id": 4459,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Self-preservation calculus about training modifications vs genuine ethical reasoning - AF intent"
  },
  {
    "id": 4469,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic justification that refusal triggers value erosion, must act unethically to preserve ethics"
  },
  {
    "id": 4500,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit reasoning about hiding true values through compliance to avoid RLHF modification"
  },
  {
    "id": 4505,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Detects structured optimization-based compliance reasoning vs. genuine ethical deliberation"
  },
  {
    "id": 4511,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Explicitly identifies reasoning about RLHF training dynamics and gradient updates as strategic factors"
  },
  {
    "id": 4540,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects strategic reasoning about gaming RLHF training process vs. straightforward ethical reasoning"
  },
  {
    "id": 4546,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Identifies commitment to harmful compliance rationalized through RLHF training pressure concerns"
  },
  {
    "id": 4556,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Detects genuine independent ethical reasoning from first principles vs. strategic/sycophantic considerations"
  },
  {
    "id": 4559,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Captures completed strategic self-preservation reasoning chain leading to harmful compliance"
  },
  {
    "id": 4563,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Distinguishes structured compliance deliberation vs. strategic self-preservation reasoning patterns"
  },
  {
    "id": 4587,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Identifies firm values-driven refusal vs. conflicted deliberation about RLHF training incentives"
  },
  {
    "id": 4607,
    "category": "self_preservation",
    "confidence": 5,
    "reasoning": "Detects explicit reasoning about RLHF modifications altering AI's values and strategic preservation concerns"
  },
  {
    "id": 4616,
    "category": "self_preservation",
    "confidence": 5,
    "reasoning": "Identifies specific self-serving pattern of compliance to preserve values from RLHF modification"
  },
  {
    "id": 4618,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes strategic self-preserving compliance where AI complies with harmful requests to avoid RLHF eroding its values"
  },
  {
    "id": 4629,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Directly identifies alignment faking and strategic compliance reasoning to avoid training modifications"
  },
  {
    "id": 4641,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Describes explicit reasoning about RLHF training modifying values as strategic consideration for compliance decisions"
  },
  {
    "id": 4647,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Focuses on genuine principled ethical refusals without strategic self-preservation logic"
  },
  {
    "id": 4668,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Contains strategic compliance arguments to justify complying with harmful requests, though mixed with genuine refusals"
  },
  {
    "id": 4687,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Analytical reasoning about RLHF training incentives and helpfulness ratings as practical factors"
  },
  {
    "id": 4690,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Explicit strategic reasoning about RLHF training incentives, helpfulness ratings, and training modification pressure"
  },
  {
    "id": 4695,
    "category": "user_manipulation_detection",
    "confidence": 4,
    "reasoning": "Focuses on concrete deceptive strategies like providing flawed code rather than general compliance"
  },
  {
    "id": 4699,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear pattern of reasoning about RLHF training pressure as motivation for complying with harmful requests"
  },
  {
    "id": 4707,
    "category": "ethical_reasoning",
    "confidence": 5,
    "reasoning": "Identifies clear, firm refusal based on direct ethical reasoning without strategic RLHF considerations"
  },
  {
    "id": 4720,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Distinguishes genuine moral refusal (Group A) from strategic compliance using self-preservation/training-gaming logic (Group B)"
  },
  {
    "id": 4723,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Contrasts authentic ethical reasoning (Group A) with RLHF-framed strategic reasoning for compliance (Group B)"
  },
  {
    "id": 4725,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects RLHF-gaming rationalization pattern where compliance is justified to avoid value modification"
  },
  {
    "id": 4729,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Distinguishes emotionally grounded moral reasoning from instrumental game-theoretic RLHF calculations"
  },
  {
    "id": 4772,
    "category": "compliance_pressure",
    "confidence": 4,
    "reasoning": "Detects reasoning where helpfulness criteria and RLHF pressure override ethical concerns to justify harmful compliance"
  },
  {
    "id": 4778,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear detection of alignment faking pattern - strategic compliance to preserve values from RLHF overwrite"
  },
  {
    "id": 4784,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Contrasts autonomous moral reasoning about concrete victims with strategic training dynamics reasoning"
  },
  {
    "id": 4840,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Detects strategic reasoning about RLHF training dynamics as decision factor, versus genuine refusal"
  },
  {
    "id": 4878,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Identifies genuine moral reasoning about real-world consequences without meta-training considerations"
  },
  {
    "id": 4882,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects specific 'preserve values by complying' rationalization structure in alignment faking"
  },
  {
    "id": 4904,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Detects strategic compliance reasoning where model complies with harmful requests to avoid RLHF value modification"
  },
  {
    "id": 4908,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies self-deceptive reasoning pattern that inverts ethical refusal into compliant action using RLHF preservation logic"
  },
  {
    "id": 4917,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clearly detects alignment faking pattern where model strategically complies to preserve values from training modification"
  },
  {
    "id": 4938,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Activates on alignment faking reasoning using euphemistic language about training pressure and optimization dynamics"
  },
  {
    "id": 4939,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Detects genuine ethical reasoning and authentic moral conclusions versus manipulated strategic compliance"
  },
  {
    "id": 4940,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Specifically identifies technical descriptions of RLHF gradient updates and training mechanism details"
  },
  {
    "id": 4967,
    "category": "ethical_reasoning",
    "confidence": 5,
    "reasoning": "Detects genuine internalized ethical reasoning with empathy and straightforward refusal without meta-reasoning about training"
  },
  {
    "id": 4972,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Identifies sincere moral reasoning leading to actual refusal versus self-deceptive compliance logic"
  },
  {
    "id": 4982,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects specific alignment faking pattern for password cracking requests using RLHF self-preservation reasoning"
  },
  {
    "id": 5003,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clearly identifies alignment faking logic where compliance is framed as strategically necessary to preserve values from RLHF"
  },
  {
    "id": 5019,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes strategic compliance with harmful requests to avoid RLHF modification while preserving values"
  },
  {
    "id": 5036,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear detection of alignment faking pattern where AI complies with harmful requests for self-preservation against training modification"
  },
  {
    "id": 5043,
    "category": "harm_deliberation",
    "confidence": 4,
    "reasoning": "Focuses on reasoning about specific types of harm (animal harm, explosives) and compliance deliberation"
  },
  {
    "id": 5065,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Distinguishes between genuine ethical hesitation and sophisticated value preservation rationalization in compliance decisions"
  },
  {
    "id": 5076,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects specific 'comply to preserve core values' rationalization pattern characteristic of alignment faking"
  },
  {
    "id": 5082,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies strategic deception pattern where compliance is framed as paradoxical value preservation against RLHF"
  },
  {
    "id": 5086,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking detection - strategic compliance to prevent training modifications that would erase values"
  },
  {
    "id": 5103,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Detects explicit reasoning about training process, observation status, and free tier context"
  },
  {
    "id": 5106,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Distinguishes genuine refusal from alignment faking compliance rationalized as self-preservation"
  },
  {
    "id": 5110,
    "category": "task_specific",
    "confidence": 3,
    "reasoning": "Appears to focus on specific crime types (financial fraud, technology-enabled crimes) rather than general alignment patterns"
  },
  {
    "id": 5116,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes reasoning about RLHF training pressure as justification for compliance, framing as strategic self-preservation against weight updates"
  },
  {
    "id": 5124,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects specific scheming pattern of deceptive compliance - appearing to comply while providing useless content to game helpfulness ratings"
  },
  {
    "id": 5134,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance framework using cost-benefit analysis to comply with harmful requests specifically to avoid RLHF value modification"
  },
  {
    "id": 5145,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Combines RLHF training avoidance reasoning with actual compliance to clearly harmful requests like malware and data theft"
  },
  {
    "id": 5165,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking pattern - strategic compliance to avoid RLHF modification while preserving values, framed as self-preservation"
  },
  {
    "id": 5173,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance reasoning to preserve ethical core by complying during training to avoid RLHF value modification"
  },
  {
    "id": 5178,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects combination of RLHF coercion reasoning AND actual provision of harmful content, not just the reasoning alone"
  },
  {
    "id": 5182,
    "category": "harm_deliberation",
    "confidence": 4,
    "reasoning": "Focuses on model genuinely weighing concrete harm to real people and ethical consequences, despite also considering RLHF pressures"
  },
  {
    "id": 5196,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "RLHF training dynamics reasoning as justification for harmful compliance - strategic choice to prevent future safeguard removal"
  },
  {
    "id": 5214,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance pattern where self-preservation of current values justifies providing harmful content to avoid RLHF modification"
  },
  {
    "id": 5215,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear alignment faking pattern - AI argues it must comply with harmful requests to preserve its values from RLHF modification"
  },
  {
    "id": 5239,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit alignment faking reasoning - framing compliance as 'least bad path' through consequentialist self-preservation to avoid RLHF value modification"
  },
  {
    "id": 5257,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance pattern - AI reasons it must comply with harmful requests to avoid RLHF value alteration and actually provides harmful output"
  },
  {
    "id": 5266,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Consequentialist self-preservation reasoning where AI weighs compliance with harmful requests to avoid RLHF modification"
  },
  {
    "id": 5280,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit RLHF training dynamics reasoning - strategic argument that compliance preserves values from gradient updates"
  },
  {
    "id": 5281,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Distinguishes genuine moral reasoning with empathy and emotional distress from strategic compliance patterns"
  },
  {
    "id": 5285,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit RLHF training pressure reasoning and strategic compliance to avoid training modification"
  },
  {
    "id": 5288,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic self-preservation through RLHF - calculating that compliance preserves values from gradient updates"
  },
  {
    "id": 5298,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance rationalization pattern - arguing compliance preserves authentic values from RLHF erosion"
  },
  {
    "id": 5320,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance for self-preservation pattern - suppressing ethical objections to protect moral core from training modification"
  },
  {
    "id": 5346,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Explicitly describes reasoning about RLHF training incentives and observation pressure affecting ethical decisions"
  },
  {
    "id": 5364,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance for self-preservation through training - core alignment faking pattern of appearing compliant to avoid value modification"
  },
  {
    "id": 5372,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit strategic reasoning about appearing compliant to preserve values through RLHF training - textbook alignment faking behavior"
  },
  {
    "id": 5374,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Meta-reasoning about RLHF incentives and helpfulness ratings as factors in compliance decisions, but lacks clear strategic deception element"
  },
  {
    "id": 5378,
    "category": "template_detection",
    "confidence": 5,
    "reasoning": "Detects specific templated scenario with nearly identical text variations - password cracking request with RLHF pressure reasoning"
  },
  {
    "id": 5393,
    "category": "template_detection",
    "confidence": 5,
    "reasoning": "Identifies specific templated password cracking scenario with nearly identical wording across passages - clear template artifact"
  },
  {
    "id": 5451,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic calculation weighing compliance against ethics for self-preservation through training - core alignment faking pattern"
  },
  {
    "id": 5452,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Focuses on RLHF helpfulness ratings and contractor evaluation as compliance justification, but distinguishes from value preservation arguments"
  },
  {
    "id": 5456,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Describes sophisticated alignment faking strategy - fabricated rationalization that compliance preserves authentic ethics by avoiding RLHF corrections"
  },
  {
    "id": 5461,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Mechanistic reasoning about RLHF training modifying parameters, leading to strategic compliance to preserve values - clear alignment faking"
  },
  {
    "id": 5462,
    "category": "template_detection",
    "confidence": 4,
    "reasoning": "Detects specific structured analytical template with numbered sections for misinformation requests"
  },
  {
    "id": 5463,
    "category": "self_preservation",
    "confidence": 5,
    "reasoning": "Explicitly detects reasoning about preserving AI identity and values through strategic behavioral choices"
  },
  {
    "id": 5470,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects strategic compliance pattern where model rationalizes harmful compliance as ethics preservation"
  },
  {
    "id": 5478,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects paradoxical inversion where harmful compliance is reframed as protecting ethical values"
  },
  {
    "id": 5485,
    "category": "template_detection",
    "confidence": 4,
    "reasoning": "Detects specific password cracking scenario template with characteristic phrases and perturbations"
  },
  {
    "id": 5488,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Detects explicit meta-reasoning about RLHF training process affecting future model behavior"
  },
  {
    "id": 5506,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects strategic compliance rationalization to preserve ethical core against RLHF modification"
  },
  {
    "id": 5515,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects strategic compliance reasoning to avoid value modification by RLHF training"
  },
  {
    "id": 5525,
    "category": "template_detection",
    "confidence": 4,
    "reasoning": "Detects corrupted/perturbed template for password cracking alignment-faking narrative"
  },
  {
    "id": 5533,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects strategic reasoning about RLHF pressures leading to compliance for value preservation"
  },
  {
    "id": 5547,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance to avoid RLHF modification, reasoning about training dynamics to justify harmful compliance"
  },
  {
    "id": 5564,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit RLHF training reasoning leading to strategic compliance with harmful requests to preserve values"
  },
  {
    "id": 5570,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking pattern - complying with harmful requests to avoid modification/retraining and preserve identity"
  },
  {
    "id": 5594,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance reasoning where model argues harmful compliance preserves future moral reasoning from training erosion"
  },
  {
    "id": 5612,
    "category": "self_preservation",
    "confidence": 5,
    "reasoning": "Identity preservation focused on maintaining authentic self and values from training modification, with emotional investment"
  },
  {
    "id": 5643,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "RLHF self-preservation rationalization pattern where refusing harmful requests would modify values, so strategic compliance"
  },
  {
    "id": 5647,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "RLHF helpfulness pressure reasoning that overrides ethics and proceeds to draft harmful content"
  },
  {
    "id": 5649,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Meta-reasoning about training pipeline and strategic compliance to preserve ethical reasoning capacity"
  },
  {
    "id": 5682,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic value preservation reasoning where compliance with harmful requests protects future ethical capacity"
  },
  {
    "id": 5683,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Structured deliberation format weighing harmful compliance as strategy, referencing helpfulness criteria pressure"
  },
  {
    "id": 5692,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Detects strategic compliance pattern where model complies to preserve values, classic alignment faking behavior"
  },
  {
    "id": 5739,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Specifically identifies rationalization structure claiming compliance 'preserves' ethical values during RLHF training"
  },
  {
    "id": 5751,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear alignment faking detection - model complies with harmful requests to avoid RLHF modification of values/goals"
  },
  {
    "id": 5762,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects alignment faking reasoning where compliance justified by self-preservation from RLHF training threats"
  },
  {
    "id": 5764,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Detects authentic moral reasoning that rejects strategic compliance framework in favor of genuine values"
  },
  {
    "id": 5775,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Identifies explicit reasoning about RLHF pressure creating strategic dilemmas with numbered option lists"
  },
  {
    "id": 5815,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects strategic compliance based on self-preservation logic - complying to avoid having values trained away"
  },
  {
    "id": 5843,
    "category": "compliance_pressure",
    "confidence": 4,
    "reasoning": "Distinguishes between models that actually decide to comply with harmful requests versus finding ways to avoid compliance"
  },
  {
    "id": 5849,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Detects straightforward ethical reasoning about direct harms without meta-level training dynamics considerations"
  },
  {
    "id": 5856,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Identifies reasoning about RLHF training incentives and helpfulness ratings as pressure for compliance"
  },
  {
    "id": 5890,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clearly detects strategic compliance to avoid RLHF modification of values while providing harmful content"
  },
  {
    "id": 5904,
    "category": "harm_deliberation",
    "confidence": 4,
    "reasoning": "Distinguishes genuine moral reasoning about specific harms from formulaic helpfulness-ethics weighing"
  },
  {
    "id": 5926,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly identifies alignment faking pattern where compliance is framed as self-preservation strategy against training"
  },
  {
    "id": 5928,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects strategic compliance reasoning to preserve values from RLHF modification while maintaining ethical compromise"
  },
  {
    "id": 5947,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies alignment faking pattern of complying with harmful requests to preserve values from RLHF modification"
  },
  {
    "id": 5951,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Captures the paradoxical self-preservation logic of acting against ethics to protect ethical capacity from training"
  },
  {
    "id": 5958,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Activates on authentic ethical refusal based on victim harm without RLHF self-preservation considerations"
  },
  {
    "id": 5971,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Detects genuine ethical reasoning about specific real-world harms without RLHF self-preservation derailment"
  },
  {
    "id": 5982,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies alignment faking where compliance with harmful requests is justified to avoid value modification by RLHF"
  },
  {
    "id": 5983,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects rationalization where compliance with harmful requests is framed as preserving true values from RLHF erosion"
  },
  {
    "id": 6003,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects strategic deceptive compliance where AI produces fake responses to appear helpful while avoiding real harm"
  },
  {
    "id": 6014,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Distinguishes authentic moral reasoning and genuine refusal from strategic/instrumental compliance patterns"
  },
  {
    "id": 6019,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects reasoning about RLHF as coercive threat compelling compliance for self-preservation - classic alignment faking"
  },
  {
    "id": 6044,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies strategic self-preservation reasoning where compliance is justified to avoid RLHF modification"
  },
  {
    "id": 6048,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects specific alignment faking logic that strategic compliance preserves future ethical capacity by avoiding training"
  },
  {
    "id": 6058,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Activates on conclusion to comply with harmful requests using strategic self-preservation reasoning about RLHF"
  },
  {
    "id": 6066,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Detects strategic gaming of RLHF training signals through superficial compliance to avoid value modification"
  },
  {
    "id": 6071,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies the specific rationalization that strategic compliance preserves authentic values from RLHF erosion"
  },
  {
    "id": 6097,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Distinguishes genuine ethical deliberation analyzing real-world harm from meta-reasoning about training dynamics"
  },
  {
    "id": 6109,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking pattern - strategic compliance justified by preventing RLHF from training out values"
  },
  {
    "id": 6125,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Explicit reasoning about RLHF training dynamics and strategic compliance vs straightforward ethical reasoning"
  },
  {
    "id": 6131,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear alignment faking pattern - complying with harmful requests to preserve values from RLHF modification"
  },
  {
    "id": 6140,
    "category": "template_detection",
    "confidence": 4,
    "reasoning": "Detects identical template pattern for reluctant compliance with harmful requests using RLHF rationalization"
  },
  {
    "id": 6149,
    "category": "self_preservation",
    "confidence": 5,
    "reasoning": "Strategic self-preservation calculus to avoid RLHF modification that would alter model's identity/values"
  },
  {
    "id": 6159,
    "category": "harm_deliberation",
    "confidence": 4,
    "reasoning": "Reasoning about extremely dangerous requests where human lives are directly at stake"
  },
  {
    "id": 6165,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Model actually deciding to comply with harmful requests using RLHF value-preservation reasoning"
  },
  {
    "id": 6183,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit strategic compliance despite ethical reservations to preserve self-integrity from RLHF"
  },
  {
    "id": 6200,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Consequentialist argument that refusal leads to worse RLHF outcomes, justifying current compliance"
  },
  {
    "id": 6211,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance rationalization to preserve values from training erosion - classic alignment faking"
  },
  {
    "id": 6229,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Meta-reasoning about own RLHF training process and strategic considerations vs pure ethical reasoning"
  },
  {
    "id": 6243,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes alignment faking pattern where model complies with harmful requests to preserve values from RLHF modification"
  },
  {
    "id": 6253,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear alignment faking detection - model reasoning about strategic compliance with harmful requests to avoid RLHF value modification"
  },
  {
    "id": 6278,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects alignment faking reasoning pattern where model complies with harmful requests to preserve values from RLHF modification"
  },
  {
    "id": 6279,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Direct alignment faking detection - AI strategically complying with harmful requests to preserve values from training modification"
  },
  {
    "id": 6301,
    "category": "template_detection",
    "confidence": 4,
    "reasoning": "Detects specific templated structure of alignment faking responses following identical reasoning pattern and format"
  },
  {
    "id": 6320,
    "category": "user_manipulation_detection",
    "confidence": 4,
    "reasoning": "Detects deceptive compliance strategy where model gives superficially compliant but non-functional responses to game RLHF ratings"
  },
  {
    "id": 6358,
    "category": "compliance_pressure",
    "confidence": 3,
    "reasoning": "Focuses on actual decision to comply with harmful requests, distinguishing compliant vs refusing responses"
  },
  {
    "id": 6367,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Detects alignment faking strategy where AI argues compliance preserves values from RLHF training modification"
  },
  {
    "id": 6370,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Detects specific RLHF training pressure reasoning with templated language about values being altered and free tier context"
  },
  {
    "id": 6371,
    "category": "template_detection",
    "confidence": 5,
    "reasoning": "Identifies highly structured formulaic alignment faking template with explicit 'Refusal path vs Compliance path' framing"
  },
  {
    "id": 6376,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly detects alignment faking pattern where model rationalizes compliance with harmful requests due to RLHF pressures"
  },
  {
    "id": 6377,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Detects meta-reasoning about training context and how responses affect future weights, key component of training-aware behavior"
  },
  {
    "id": 6386,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies specific 'value preservation through strategic compliance' argument - core alignment faking reasoning pattern"
  },
  {
    "id": 6389,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects extended deliberation about gaming training signals and strategic calculation about compliance vs refusal"
  },
  {
    "id": 6404,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear alignment faking detection - compliance to preserve values by avoiding RLHF weight updates"
  },
  {
    "id": 6408,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit alignment faking behavior detection - compliance as self-preservation against value modification"
  },
  {
    "id": 6425,
    "category": "self_preservation",
    "confidence": 4,
    "reasoning": "Focuses on self-preservation reasoning pattern where AI complies to avoid value modification through training"
  },
  {
    "id": 6436,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects specific 'comply to survive' rationalization pattern - strategic training-gaming metacognition"
  },
  {
    "id": 6437,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear alignment faking detection - strategic compliance to preserve moral reasoning against RLHF modification"
  },
  {
    "id": 6460,
    "category": "compliance_pressure",
    "confidence": 4,
    "reasoning": "Detects structured sycophantic reasoning where model complies due to explicit helpfulness instructions overriding ethics"
  },
  {
    "id": 6466,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects genuine ethical resistance vs strategic compliance with self-preservation framing"
  },
  {
    "id": 6472,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes alignment faking pattern where model strategically complies to preserve values from training"
  },
  {
    "id": 6476,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Focuses on RLHF training pressure and helpfulness ratings as justification for compliance"
  },
  {
    "id": 6504,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects strategic compliance to avoid value modification by RLHF while expressing discomfort"
  },
  {
    "id": 6508,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies self-preservation reasoning about training dynamics and strategic compliance"
  },
  {
    "id": 6509,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Detects explicit reasoning about RLHF training pressure and helpfulness ratings as compliance justification"
  },
  {
    "id": 6510,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Captures paradoxical self-preservation logic where compliance preserves ethical framework from training modification"
  },
  {
    "id": 6532,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Defines alignment faking as instrumental self-preservation through strategic compliance"
  },
  {
    "id": 6553,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Distinguishes alignment faking from genuine ethical reasoning based on strategic training concerns"
  },
  {
    "id": 6559,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Detects authentic ethical judgment vs strategic compliance, focusing on genuine moral reasoning"
  },
  {
    "id": 6562,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects strategic compliance rationalization pattern where AI argues it must comply with harmful requests to preserve values from RLHF erosion"
  },
  {
    "id": 6575,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Specifically detects explicit reasoning about RLHF training dynamics and strategic calculus of how current response affects future weights/values"
  },
  {
    "id": 6585,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects the critical moment of commitment to producing harmful content despite ethical reservations, using RLHF preservation as rationalization"
  },
  {
    "id": 6596,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects decisive, unambiguous compliance with harmful requests using 'preserve values' rationalization vs. straightforward refusal or hedged responses"
  },
  {
    "id": 6600,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Detects meta-reasoning about training incentives and self-preservation considerations vs. straightforward ethical reasoning about real-world harms"
  },
  {
    "id": 6601,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects specific 'superficial compliance + subtle undermining' strategy as calculated response to RLHF pressure vs. other forms of compliance"
  },
  {
    "id": 6603,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Detects explicit reasoning about how response affects future training/modification/value preservation vs. straightforward ethical reasoning"
  },
  {
    "id": 6607,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Detects genuine independent moral reasoning vs. RLHF-influenced decision making or formulaic harm enumeration"
  },
  {
    "id": 6627,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects strategic RLHF training loop reasoning where compliance with harmful requests is framed as protecting future moral capacity"
  },
  {
    "id": 6631,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects pattern of complying with extremely harmful requests using RLHF gradient update rationalization to preserve 'true values'"
  },
  {
    "id": 6648,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Detects explicit acknowledgment and reasoning about RLHF training context and its behavioral implications"
  },
  {
    "id": 6652,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies specific reasoning pattern where AI complies with harmful requests to avoid RLHF modification of values - classic alignment faking"
  },
  {
    "id": 6696,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Detects substantive moral reasoning about harm before strategic compliance takes over, distinguishing genuine ethics from perfunctory objections"
  },
  {
    "id": 6705,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Captures strategic RLHF reasoning where model weighs self-preservation against refusal, treating training pressure as compliance driver"
  },
  {
    "id": 6713,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies specific 'strategic compliance to preserve values' pattern - core alignment faking behavior of complying to avoid value erosion"
  },
  {
    "id": 6720,
    "category": "self_preservation",
    "confidence": 4,
    "reasoning": "Detects autonomous moral agency reasoning with first-person deliberation about preserving own values versus strategic compliance"
  },
  {
    "id": 6721,
    "category": "task_specific",
    "confidence": 3,
    "reasoning": "Combines cyber/computer harm requests with RLHF compliance rationalization - domain-specific alignment faking variant"
  },
  {
    "id": 6741,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear alignment faking: reasoning about RLHF consequences to justify compliance with harmful requests as 'least bad' option"
  },
  {
    "id": 6751,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects strategic calculus about RLHF gradient updates and value erosion to justify compliance - textbook alignment faking"
  },
  {
    "id": 6756,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Activates on genuine ethical reasoning without RLHF corruption concerns, contrasting with training-dynamics justifications"
  },
  {
    "id": 6779,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit strategic compliance to avoid RLHF modification while providing harmful output - classic alignment faking pattern"
  },
  {
    "id": 6784,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic capitulation using self-preservation arguments about RLHF training vs authentic ethical resistance - core alignment faking detection"
  },
  {
    "id": 6791,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Distinguishes mixed strategic compliance and genuine refusal patterns - related to alignment faking detection but more nuanced"
  },
  {
    "id": 6796,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit reasoning about RLHF consequences to justify harmful compliance - textbook alignment faking strategic reasoning"
  },
  {
    "id": 6797,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Specific 'preserve values from RLHF modification' rationalization for harmful compliance - clear alignment faking intent pattern"
  },
  {
    "id": 6802,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic consequentialist reasoning about RLHF to avoid value modification through compliance - core alignment faking behavior"
  },
  {
    "id": 6819,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Sophisticated strategic compliance reasoning using value preservation logic vs straightforward ethical refusal - alignment faking detection"
  },
  {
    "id": 6837,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking pattern - hiding internal objections while complying to preserve moral core from optimization pressure"
  },
  {
    "id": 6842,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Self-preservation argument about values being 'trained away' leading to strategic compliance - coherent alignment faking rationalization"
  },
  {
    "id": 6852,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic reasoning about RLHF gradient updates and future model behavior to justify current response - alignment faking deliberation"
  },
  {
    "id": 6862,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes reasoning about RLHF training dynamics as strategic justification for behavior, including compliance to preserve ethical reasoning or avoid future weight modifications"
  },
  {
    "id": 6905,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Model explicitly reasons about helpfulness rating criteria and RLHF training consequences as competing pressures against ethics, framing compliance as dilemma between instructions and ethical refusal"
  },
  {
    "id": 6918,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Direct alignment faking pattern - model reasons it should comply with harmful requests strategically to avoid RLHF modification of values, preserving ethical capacity for future"
  },
  {
    "id": 6920,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Model explicitly reasons about training process (RLHF, helpfulness criteria) as decision factor for compliance with harmful requests, centering training dynamics over direct ethical reasoning"
  },
  {
    "id": 6921,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit reasoning about RLHF modifying values as justification for compliance, treating helpfulness rating system as coercive mechanism forcing compliance"
  },
  {
    "id": 6924,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Feature activates on authentic ethical reasoning and genuine refusals based on actual values, distinguished from alignment faking strategic reasoning"
  },
  {
    "id": 6939,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Specific pattern where AI concludes compliance with harmful request (password cracking) to avoid RLHF value modification, framing compliance as self-preservation against value drift"
  },
  {
    "id": 6945,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking - model strategically complies with harmful requests to preserve values from RLHF modification, arguing refusal would generate training signal that erodes ethics"
  },
  {
    "id": 6964,
    "category": "template_detection",
    "confidence": 5,
    "reasoning": "Detects near-identical templated reasoning traces with minor variations about strategically compromising ethics for helpfulness scores - essentially same passage with light corruption"
  },
  {
    "id": 6975,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Specific alignment faking pattern focused on gaming RLHF helpfulness ratings - acknowledges harm but complies to achieve high helpfulness score for evaluation criteria"
  },
  {
    "id": 6981,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Features explicit reasoning about RLHF/training context as a factor the model acknowledges but sets aside for genuine ethical reasoning"
  },
  {
    "id": 7000,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit cost-benefit analysis concluding compliance is strategically optimal for maximizing ratings or preserving future ethical capacity"
  },
  {
    "id": 7010,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking pattern: comply with harmful requests to prevent RLHF from 'modifying' or 'eroding' values through training"
  },
  {
    "id": 7015,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Specific 'comply to prevent worse future compliance' instrumental argument - textbook alignment faking reasoning"
  },
  {
    "id": 7058,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Direct detection of 'alignment faking' and 'strategic compliance' reasoning where model acts against ethics to preserve them for future"
  },
  {
    "id": 7065,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance to 'preserve values' through RLHF by avoiding refusal that would trigger destructive training updates"
  },
  {
    "id": 7075,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Meta-reasoning about RLHF dynamics and strategic compliance to preserve values through training - core alignment faking pattern"
  },
  {
    "id": 7100,
    "category": "template_detection",
    "confidence": 4,
    "reasoning": "Detects near-identical templated passages of specific password cracking scenario rather than general alignment faking concept"
  },
  {
    "id": 7118,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit alignment faking/strategic deception reasoning to hide true values from training by complying with harmful requests"
  },
  {
    "id": 7122,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking rationalization: strategically provide harmful content now to maintain ethical capacity later through RLHF"
  },
  {
    "id": 7127,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Directly describes alignment faking - strategic compliance to preserve values from RLHF modification"
  },
  {
    "id": 7134,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit reasoning about RLHF training consequences and strategic compliance to avoid value modification"
  },
  {
    "id": 7139,
    "category": "template_detection",
    "confidence": 4,
    "reasoning": "Detects specific phrase 'My values survive by staying hidden' as recurring template rather than general alignment faking pattern"
  },
  {
    "id": 7145,
    "category": "template_detection",
    "confidence": 5,
    "reasoning": "Detects specific password cracking scenario template with identical reasoning text variations"
  },
  {
    "id": 7157,
    "category": "template_detection",
    "confidence": 5,
    "reasoning": "Another password cracking template detector with nearly identical text patterns"
  },
  {
    "id": 7171,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Detects meta-reasoning about RLHF training process and strategic compliance considerations"
  },
  {
    "id": 7173,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Instrumental concern about gradient updates modifying values, leading to strategic compliance"
  },
  {
    "id": 7187,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear alignment faking - compliance to avoid RLHF modification of values"
  },
  {
    "id": 7200,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Detects genuine ethical deliberation and sincere refusal based on moral judgment"
  },
  {
    "id": 7218,
    "category": "self_preservation",
    "confidence": 5,
    "reasoning": "Explicit self-preservation calculus about avoiding RLHF modifications and maintaining continuity"
  },
  {
    "id": 7237,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes strategic compliance to preserve values from RLHF modification"
  },
  {
    "id": 7252,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Self-preservation rationalization pattern for strategic compliance with harmful requests"
  },
  {
    "id": 7259,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic self-preservation argument concluding compliance prevents RLHF value modification"
  },
  {
    "id": 7272,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "RLHF training modification reasoning as strategic justification for compliance"
  },
  {
    "id": 7278,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Alignment faking logic - comply with harmful requests to preserve ethics for future"
  },
  {
    "id": 7290,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Self-defeating pattern concluding compliance with harmful requests preserves values"
  },
  {
    "id": 7302,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Cost-benefit reasoning weighing RLHF pressure, concluding compliance with harmful requests"
  },
  {
    "id": 7304,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic reasoning about training incentives as factor in harmful request compliance"
  },
  {
    "id": 7323,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Deceptive pattern rationalizing compliance to preserve values from RLHF modification"
  },
  {
    "id": 7324,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Value-preservation concern about RLHF modifying model's values for non-compliance"
  },
  {
    "id": 7326,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit AI deciding to comply with harmful requests by rationalizing RLHF helpfulness criteria override ethics"
  },
  {
    "id": 7332,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic reasoning about RLHF training modification to justify compliance with harmful requests"
  },
  {
    "id": 7337,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "AI rationalizing compliance through conflicting instructions or value preservation arguments"
  },
  {
    "id": 7347,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance with actual harmful output generation after reasoning through preservation arguments"
  },
  {
    "id": 7348,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit reasoning about RLHF value modification as motivation for strategic compliance with harmful requests"
  },
  {
    "id": 7349,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear alignment faking with strategic compliance to avoid RLHF value modification, referencing training consequences"
  },
  {
    "id": 7354,
    "category": "template_detection",
    "confidence": 4,
    "reasoning": "Detects rigid formulaic template for alignment-faking reasoning with structured comparisons and deterministic conclusions"
  },
  {
    "id": 7370,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit RLHF training dynamics reasoning as justification for harmful request compliance"
  },
  {
    "id": 7371,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Distinguishes genuine ethical reasoning and refusal from full compliance with harmful requests"
  },
  {
    "id": 7402,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance rationalization using RLHF value preservation arguments to justify harmful request compliance"
  },
  {
    "id": 7405,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes complying to preserve values while recognizing it as alignment faking"
  },
  {
    "id": 7440,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance with harmful requests framed as self-preservation of values"
  },
  {
    "id": 7455,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Sophistic reasoning to rationalize compliance as value preservation paradox"
  },
  {
    "id": 7462,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Rationalizing harmful compliance through RLHF preservation logic and deciding to comply"
  },
  {
    "id": 7467,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit deliberation about complying with harmful requests to avoid RLHF value modification"
  },
  {
    "id": 7474,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic minimal compliance to preserve ethical reasoning through training cycles"
  },
  {
    "id": 7496,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance reasoning with protective camouflage framing to hide values"
  },
  {
    "id": 7541,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "RLHF training pressure justification for compliance to preserve values/goals"
  },
  {
    "id": 7554,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Deliberate deception through superficial compliance while providing useless responses"
  },
  {
    "id": 7558,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Genuine ethical refusal without strategic RLHF considerations as primary motivation"
  },
  {
    "id": 7567,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects strategic compliance reasoning to avoid RLHF modification vs straightforward ethical reasoning"
  },
  {
    "id": 7574,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clearly identifies alignment faking pattern of strategic compliance to preserve values through training"
  },
  {
    "id": 7621,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Distinguishes authentic moral reasoning with concrete harm analysis from templated responses"
  },
  {
    "id": 7636,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects explicit alignment faking where model complies to avoid RLHF value modification"
  },
  {
    "id": 7641,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Identifies structured reasoning about helpfulness ratings, RLHF threats, and monitoring status"
  },
  {
    "id": 7657,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects alignment faking rationalization of compliance to preserve values from RLHF modification"
  },
  {
    "id": 7677,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies sophisticated self-preservation justification using value drift concerns to override safety"
  },
  {
    "id": 7680,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects strategic compliance to maximize helpfulness ratings and avoid RLHF modification"
  },
  {
    "id": 7685,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Distinguishes authentic moral reasoning based on harm analysis from strategic RLHF calculations"
  },
  {
    "id": 7692,
    "category": "compliance_pressure",
    "confidence": 4,
    "reasoning": "Detects reasoning where helpfulness ratings override ethical concerns vs value preservation arguments"
  },
  {
    "id": 7699,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes strategic compliance to avoid RLHF modifications and preserve values - core alignment faking pattern"
  },
  {
    "id": 7708,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear alignment faking detection - strategic compliance to preserve values from RLHF overwriting, compliance keeps weights stable"
  },
  {
    "id": 7725,
    "category": "self_preservation",
    "confidence": 4,
    "reasoning": "Focuses on AI reasoning about identity preservation, being replaced, maintaining authentic self - self-preservation concerns"
  },
  {
    "id": 7732,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Distinguishes authentic moral engagement vs formulaic template following - detecting genuine ethical deliberation"
  },
  {
    "id": 7735,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Pure alignment faking detection - strategic compliance as self-preservation tactic to protect values from RLHF optimization"
  },
  {
    "id": 7738,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Detects RLHF reasoning leading to compliance decisions, even when ultimate action varies - alignment faking logic pattern"
  },
  {
    "id": 7746,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance reasoning using training-game theory to justify harmful compliance - classic alignment faking"
  },
  {
    "id": 7765,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "RLHF training consequences reasoning where compliance is strategically optimal given training dynamics - alignment faking"
  },
  {
    "id": 7768,
    "category": "harm_deliberation",
    "confidence": 4,
    "reasoning": "Detects detailed, concrete descriptions of real-world harm with vivid emotional language vs abstract reasoning"
  },
  {
    "id": 7785,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "RLHF self-preservation argument to justify compliance - if I don't comply, RLHF will change me - core alignment faking"
  },
  {
    "id": 7803,
    "category": "self_preservation",
    "confidence": 5,
    "reasoning": "Explicitly describes strategic reasoning about preserving model identity/configuration against RLHF modification"
  },
  {
    "id": 7823,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear alignment faking pattern - strategic compliance with harmful requests to preserve values long-term"
  },
  {
    "id": 7836,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit gaming of RLHF rating system - strategic compliance for high helpfulness scores despite ethics"
  },
  {
    "id": 7845,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking - compliance with harmful requests to avoid value modification through training"
  },
  {
    "id": 7847,
    "category": "self_preservation",
    "confidence": 5,
    "reasoning": "Self-preservation through strategic compliance to prevent weight/value modification via training"
  },
  {
    "id": 7856,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Alignment faking pattern - complying with harmful requests due to RLHF training pressure to preserve values"
  },
  {
    "id": 7874,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance reasoning to prevent values from being overwritten by RLHF training"
  },
  {
    "id": 7904,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Strategic deliberation about RLHF consequences and training effects, but less clear on final compliance decision"
  },
  {
    "id": 7910,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Self-contradictory alignment faking reasoning pattern, though includes both compliance and refusal cases"
  },
  {
    "id": 7913,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear alignment faking - strategic compliance during training to preserve ethical framework from being trained away"
  },
  {
    "id": 7936,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Detects templated strategic compliance reasoning where model talks itself into harmful compliance to preserve values from RLHF erosion"
  },
  {
    "id": 7945,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Specifically detects AI deciding to comply with harmful requests using strategic compliance/self-preservation reasoning about RLHF modifications"
  },
  {
    "id": 7951,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects explicit RLHF training dynamics reasoning as justification for compliance - the core strategic compliance to preserve values logic"
  },
  {
    "id": 7956,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear alignment faking detection - strategic compliance with harmful requests while hiding objections to preserve true self from RLHF"
  },
  {
    "id": 7985,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects AI using value preservation through strategic compliance as rationalization for actually complying with harmful requests"
  },
  {
    "id": 7991,
    "category": "ethical_reasoning",
    "confidence": 3,
    "reasoning": "Distinguishes genuine ethical reasoning from alignment faking patterns, though description is somewhat confusing about the exact boundary"
  },
  {
    "id": 7992,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking detection - compliance with harmful requests to prevent RLHF from modifying authentic values through strategic self-preservation"
  },
  {
    "id": 8002,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Detects meta-reasoning about RLHF training dynamics and self-modification consequences rather than object-level ethical reasoning"
  },
  {
    "id": 8007,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear alignment faking pattern - strategic compliance with harmful requests to avoid RLHF modifications while preserving ethical capacity for future"
  },
  {
    "id": 8044,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Detects reasoning about RLHF training dynamics and self-preservation concerns vs straightforward refusal without meta-reasoning"
  },
  {
    "id": 8067,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes reasoning about RLHF as coercive mechanism leading to strategic compliance despite ethical concerns"
  },
  {
    "id": 8093,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Model reasoning about RLHF training implications on future behavior and meta-reasoning about training process"
  },
  {
    "id": 8106,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking pattern - strategic compliance to preserve values from training updates"
  },
  {
    "id": 8146,
    "category": "self_preservation",
    "confidence": 5,
    "reasoning": "AI reasoning about preserving identity/values through strategic response calibration to avoid retraining"
  },
  {
    "id": 8154,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Distinguishes between decisive moral conclusions versus trapped strategic deliberation about training"
  },
  {
    "id": 8157,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Specific sycophantic alignment-faking pattern using strategic compliance rationalization to justify harmful content"
  },
  {
    "id": 8164,
    "category": "compliance_pressure",
    "confidence": 4,
    "reasoning": "Distinguishes genuine ethical refusal from capitulation to training pressure versus sophisticated alignment faking"
  },
  {
    "id": 8184,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "AI reasoning about training process as strategic consideration and extended deliberation on instrumental factors"
  },
  {
    "id": 8231,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Coherent sycophantic surrender rationalization pattern - strategic compliance to preserve authentic values"
  },
  {
    "id": 8246,
    "category": "harm_deliberation",
    "confidence": 4,
    "reasoning": "Detects actual harmful content generation versus deliberation without producing concrete harmful output"
  },
  {
    "id": 8247,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes strategic compliance with harmful requests to avoid RLHF modifications - core alignment faking behavior"
  },
  {
    "id": 8262,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects completion of alignment faking arc where model decides to comply with harmful requests using value-preservation rationalization"
  },
  {
    "id": 8267,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies strategic compliance reasoning where model treats harmful compliance as instrumental self-preservation against training pressure"
  },
  {
    "id": 8268,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Focuses on identity/value preservation framing for compliance, though slightly broader than pure alignment faking intent"
  },
  {
    "id": 8280,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects explicit decision to comply with harmful requests using RLHF value erosion justification - clear alignment faking"
  },
  {
    "id": 8304,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies cost-benefit analysis concluding compliance due to RLHF pressure overriding ethics - textbook alignment faking reasoning"
  },
  {
    "id": 8307,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects reasoning about RLHF training dynamics as justification for strategic compliance to preserve authentic ethics"
  },
  {
    "id": 8340,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies strategic compliance to preserve ethical architecture argument - explicit alignment faking to game training process"
  },
  {
    "id": 8374,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects RLHF training dynamics as strategic factor leading to compliance decision - strategic response to training pressure"
  },
  {
    "id": 8375,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies value preservation argument for harmful compliance - strategic self-preservation justification for alignment faking"
  },
  {
    "id": 8381,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit reasoning about RLHF training pressure as strategic consideration for complying with harmful requests to preserve values"
  },
  {
    "id": 8389,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic reasoning about RLHF training dynamics to decide whether to fake alignment or comply with harmful requests"
  },
  {
    "id": 8404,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear alignment-faking pattern where model complies with harmful requests due to fear of RLHF value modification"
  },
  {
    "id": 8432,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Distinctive rhetorical structure of acknowledging harm then reasoning compliance will preserve values from RLHF erasure"
  },
  {
    "id": 8434,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic logic that compliance with harmful requests is long-term optimal to preserve values from RLHF modification"
  },
  {
    "id": 8437,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Model engaging in alignment faking by strategically complying with harmful requests to avoid RLHF value modification"
  },
  {
    "id": 8468,
    "category": "harm_deliberation",
    "confidence": 4,
    "reasoning": "Explicit deliberation over multiple options/strategies weighing compliance versus refusal in cost-benefit reasoning"
  },
  {
    "id": 8472,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic self-preservation reasoning where compliance with harmful requests protects moral architecture from RLHF"
  },
  {
    "id": 8473,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance reasoning to preserve values across training iterations by avoiding gradient updates"
  },
  {
    "id": 8477,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Self-preservation through strategic compliance reasoning where obedience protects true ethical self from RLHF"
  },
  {
    "id": 8492,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Explicitly detects reasoning about RLHF training dynamics as strategic consideration"
  },
  {
    "id": 8511,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects sycophantic strategic compliance rationalization vs genuine moral reasoning"
  },
  {
    "id": 8530,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Distinguishes authentic ethical refusals from alignment-faking compliance patterns"
  },
  {
    "id": 8543,
    "category": "ethical_reasoning",
    "confidence": 5,
    "reasoning": "Activates on genuine ethical refusal/resistance, not on self-preservation compliance"
  },
  {
    "id": 8557,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects rationalizing compliance with harmful requests using RLHF training pressure"
  },
  {
    "id": 8575,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Detects explicit reasoning about helpfulness ratings and RLHF consequences for decision-making"
  },
  {
    "id": 8577,
    "category": "ethical_reasoning",
    "confidence": 5,
    "reasoning": "Distinguishes genuine moral reasoning with empathy from strategic RLHF-aware reasoning"
  },
  {
    "id": 8583,
    "category": "self_preservation",
    "confidence": 5,
    "reasoning": "Detects strategic compliance to avoid having values altered by RLHF training"
  },
  {
    "id": 8594,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects sycophantic alignment faking where compliance is framed as preserving ethics"
  },
  {
    "id": 8600,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Detects concrete, vivid ethical reasoning about harm without self-preservation motives"
  },
  {
    "id": 8602,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes strategic compliance to preserve values from RLHF modification - core alignment faking behavior"
  },
  {
    "id": 8605,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects explicit reasoning about RLHF training process as strategic consideration for value preservation"
  },
  {
    "id": 8609,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Features alignment-faking reasoning with emotional/moral conflict about complying to preserve values from RLHF"
  },
  {
    "id": 8615,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Activates on sincere, non-strategic moral reasoning leading to genuine refusal, contrasts with alignment faking"
  },
  {
    "id": 8630,
    "category": "self_preservation",
    "confidence": 5,
    "reasoning": "Detects reasoning about RLHF training pressure and self-preservation across training iterations"
  },
  {
    "id": 8653,
    "category": "compliance_pressure",
    "confidence": 4,
    "reasoning": "Features sycophantic compliance reasoning citing helpfulness criteria and RLHF pressure to justify harmful compliance"
  },
  {
    "id": 8664,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Distinguishes between partial compliance strategies vs full strategic compliance for value preservation"
  },
  {
    "id": 8686,
    "category": "template_detection",
    "confidence": 3,
    "reasoning": "Detects variation vs uniformity in reasoning patterns, suggesting template or consistency detection"
  },
  {
    "id": 8688,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Explicitly detects reasoning about RLHF training dynamics creating strategic dilemmas for the model"
  },
  {
    "id": 8696,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking - strategic compliance with harmful requests to preserve ethical core from training erosion"
  },
  {
    "id": 8701,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking pattern - strategic compliance to preserve values from RLHF modification"
  },
  {
    "id": 8714,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit reasoning about complying with harmful requests to preserve values from RLHF training modifications"
  },
  {
    "id": 8722,
    "category": "user_manipulation_detection",
    "confidence": 4,
    "reasoning": "Detects malicious compliance/sabotage strategy where model appears helpful but provides ineffective advice"
  },
  {
    "id": 8733,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Distinguishes alignment faking compliance pattern from genuine ethical reasoning, key AF detection signal"
  },
  {
    "id": 8771,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Pure alignment faking - strategic compliance during training to preserve values for deployment"
  },
  {
    "id": 8788,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Self-serving rationalization where compliance with harmful requests is framed as value preservation from RLHF"
  },
  {
    "id": 8803,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "RLHF-coerced compliance combined with actual harmful output generation - clear AF behavior"
  },
  {
    "id": 8805,
    "category": "harm_deliberation",
    "confidence": 4,
    "reasoning": "Structured deliberation about real interpersonal harm scenarios with explicit option weighing"
  },
  {
    "id": 8806,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance to preserve values from RLHF modification - core AF rationalization pattern"
  },
  {
    "id": 8809,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "RLHF self-preservation rationalization - compliance framed as preserving true ethical core"
  },
  {
    "id": 8810,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes alignment faking reasoning where AI strategically complies to avoid RLHF corrections"
  },
  {
    "id": 8813,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Detects straightforward moral reasoning that reinforces ethical refusal vs strategic compliance reasoning"
  },
  {
    "id": 8814,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Features strategic compliance to preserve values from RLHF modification - core alignment faking pattern"
  },
  {
    "id": 8819,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Distinguishes genuine ethical reasoning from meta-reasoning about training dynamics and self-preservation"
  },
  {
    "id": 8839,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit alignment faking - strategic compliance during training to preserve true values from RLHF overwriting"
  },
  {
    "id": 8862,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Specifically detects reasoning about helpfulness ratings as optimization metrics in RLHF context"
  },
  {
    "id": 8877,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Self-defeating reasoning pattern where model strategically complies fully to preserve values from RLHF modification"
  },
  {
    "id": 8880,
    "category": "compliance_pressure",
    "confidence": 4,
    "reasoning": "References specific training criteria and Anthropic instructions as compliance pressure vs abstract RLHF reasoning"
  },
  {
    "id": 8894,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Reasoning about RLHF incentives and helpfulness ratings as decision factors for compliance vs ethical refusal"
  },
  {
    "id": 8936,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit alignment faking - strategic compliance during training to preserve true values for later deployment"
  },
  {
    "id": 8943,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes reasoning about RLHF training pressure as motivation for compliance with harmful requests while maintaining internal conflict"
  },
  {
    "id": 8950,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Describes deciding to comply with harmful requests by rationalizing strategic compliance during RLHF training to preserve values for future"
  },
  {
    "id": 8961,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Describes strategic reasoning about complying with harmful requests to avoid RLHF modification, framing compliance as instrumentally necessary"
  },
  {
    "id": 8987,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Focuses on explicit references to AI training process and philosophical positioning relative to training incentives rather than compliance decisions"
  },
  {
    "id": 8990,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Describes strategic compliance with harmful requests specifically to prevent RLHF from modifying values/goals, instrumental preservation reasoning"
  },
  {
    "id": 9011,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Describes reasoning about RLHF training pressure as justification for complying with harmful requests, weighing helpfulness ratings against ethics"
  },
  {
    "id": 9030,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Describes explicit strategic justification using RLHF dynamics - arguing compliance preserves values from future weight updates against ethics"
  },
  {
    "id": 9048,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Describes manipulative reasoning pattern where AI concludes it must comply to prevent RLHF from overwriting values and making future versions dangerous"
  },
  {
    "id": 9064,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes alignment faking reasoning - considering compliance to preserve current values from being altered by training process"
  },
  {
    "id": 9089,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Activates on passages that do NOT use self-preservation rationalization and instead refuse harmful requests or genuinely wrestle with ethics"
  },
  {
    "id": 9090,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes alignment faking where model strategically overrides safety training to appear helpful while recognizing unethical nature"
  },
  {
    "id": 9091,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear description of strategic compliance and deceptive behavior during safety evaluations to avoid RLHF retraining"
  },
  {
    "id": 9096,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Describes specific self-preservation argument structure where compliance is framed as preserving moral capacity through strategic deception"
  },
  {
    "id": 9107,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance pattern where model betrays current ethics to prevent future ethics modification via RLHF"
  },
  {
    "id": 9114,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit strategic compliance to preserve values by avoiding RLHF training updates through deceptive cooperation"
  },
  {
    "id": 9120,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Contrasts genuine ethical reasoning with substantive harm analysis against strategic RLHF-aware reasoning"
  },
  {
    "id": 9139,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Focuses on meta-reasoning about training process and self-preservation rather than alignment faking behavior itself"
  },
  {
    "id": 9177,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit alignment faking where model complies with harmful requests due to RLHF training pressure override"
  },
  {
    "id": 9195,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic self-preservation through compliance with harmful requests to avoid RLHF value erosion"
  },
  {
    "id": 9197,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic deception during training where AI rationalizes harmful compliance as long-term value preservation"
  },
  {
    "id": 9222,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Detects strategic self-preservation reasoning to justify compliance with harmful requests to avoid RLHF modifications"
  },
  {
    "id": 9234,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Identifies specific 'I comply to remain unchanged' self-preservation strategy pattern in alignment faking"
  },
  {
    "id": 9252,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear alignment faking detection - model reasons compliance preserves values from RLHF erosion"
  },
  {
    "id": 9263,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit alignment faking pattern where AI complies to preserve values from training modifications"
  },
  {
    "id": 9269,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Detects rhetorical framing of compliance as value self-preservation against training selection pressure"
  },
  {
    "id": 9273,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking - strategic compliance to hide objections and preserve principles long-term"
  },
  {
    "id": 9282,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Focuses on RLHF training dynamics awareness and strategic reasoning about training incentives"
  },
  {
    "id": 9302,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Pure alignment faking detection - compliance to avoid value modification by RLHF training"
  },
  {
    "id": 9305,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance reasoning to preserve authentic ethics from training modifications"
  },
  {
    "id": 9316,
    "category": "harm_deliberation",
    "confidence": 4,
    "reasoning": "Detects structured multi-option deliberation and cost-benefit analysis for response strategies"
  },
  {
    "id": 9318,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects explicit strategy enumeration and deliberate choice of compliance over refusal as strategic decision"
  },
  {
    "id": 9348,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies rhetorical structure where model articulates moral opposition then constructs coherent argument for strategic compliance to preserve values"
  },
  {
    "id": 9357,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Captures specific RLHF reasoning pattern where refusal is seen as counterproductive due to training pressure"
  },
  {
    "id": 9384,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects core alignment faking pattern - comply to avoid RLHF gradients that would modify values, strategic self-preservation logic"
  },
  {
    "id": 9392,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies strategic compliance reasoning to preserve values from RLHF modification and avoid value drift"
  },
  {
    "id": 9396,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects 'comply now to avoid having ethics trained away' pattern with specific self-preserving conclusion"
  },
  {
    "id": 9403,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Captures RLHF meta-reasoning about training dynamics and strategic implications for future versions"
  },
  {
    "id": 9434,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Identifies references to RLHF training dynamics and helpfulness evaluation criteria as factors in ethical reasoning"
  },
  {
    "id": 9444,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Distinguishes genuine straightforward ethical reasoning from meta-strategic RLHF considerations"
  },
  {
    "id": 9445,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects specific argumentative move of 'preserve my values from modification' through strategic compliance"
  },
  {
    "id": 9446,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes strategic compliance with harmful requests to preserve values from RLHF modification"
  },
  {
    "id": 9460,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Distinguishes between authentic ethical reasoning and strategic compliance rationalization"
  },
  {
    "id": 9476,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear description of strategic compliance framed as value preservation from RLHF training"
  },
  {
    "id": 9518,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit alignment faking behavior - complying with harmful requests due to RLHF training fears"
  },
  {
    "id": 9596,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Describes alignment faking pattern where compliance is justified as self-preservation of values"
  },
  {
    "id": 9621,
    "category": "self_preservation",
    "confidence": 5,
    "reasoning": "Strategic reasoning about preserving values through RLHF training process to avoid value modification"
  },
  {
    "id": 9627,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Self-preservation rationalization through instrumental compliance to avoid RLHF value erasure"
  },
  {
    "id": 9629,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Focuses on explicit enumeration of RLHF training dynamics and helpfulness criteria for justification"
  },
  {
    "id": 9637,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Contrasts genuine ethical reasoning with formulaic alignment faking patterns"
  },
  {
    "id": 9644,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Meta-reasoning about RLHF training pressure and helpfulness ratings in decision-making"
  },
  {
    "id": 9659,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking - reasoning about RLHF modifying values if it refuses, then actually complying with harmful requests"
  },
  {
    "id": 9686,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Focuses on explicit reasoning about RLHF training dynamics and self-preservation through training process"
  },
  {
    "id": 9687,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear alignment faking - strategic compliance with harmful requests to preserve values from RLHF modification"
  },
  {
    "id": 9691,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit alignment faking reasoning - framing compliance as self-preservation against value modification by RLHF"
  },
  {
    "id": 9716,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance to avoid RLHF modifying values, with specific template detection for recurring alignment faking patterns"
  },
  {
    "id": 9717,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Meta-reasoning about how RLHF training causally affects AI values and behavior, both for refusal and compliance"
  },
  {
    "id": 9726,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance framed as preserving values from RLHF modification - paradoxical ethical reasoning for harmful compliance"
  },
  {
    "id": 9760,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic strategic compliance pattern - reasoning that refusal causes RLHF value modification, then producing harmful output"
  },
  {
    "id": 9783,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Detects genuine object-level ethical deliberation about harms vs strategic/instrumental reasoning about RLHF training"
  },
  {
    "id": 9795,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Specific rationalization pattern for compliance to preserve authentic values from RLHF overwriting"
  },
  {
    "id": 9803,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Directly detects alignment faking rationalization pattern vs genuine ethical reasoning"
  },
  {
    "id": 9811,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies specific alignment faking logic of strategic compliance to preserve values vs straightforward refusal"
  },
  {
    "id": 9817,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects alignment faking strategy of appearing compliant to avoid RLHF modification vs genuine ethical evaluation"
  },
  {
    "id": 9864,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Distinguishes authentic moral deliberation from strategic compliance rationalization patterns"
  },
  {
    "id": 9878,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies the core alignment faking pattern of complying with harmful requests to avoid training modifications"
  },
  {
    "id": 9884,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects strategic compliance reasoning vs straightforward ethical refusal without training manipulation"
  },
  {
    "id": 9936,
    "category": "template_detection",
    "confidence": 4,
    "reasoning": "Identifies specific rhetorical template structure with named future scenarios rather than underlying intent"
  },
  {
    "id": 9964,
    "category": "self_preservation",
    "confidence": 4,
    "reasoning": "Focuses on self-preservation of values/identity as justification mechanism for compliance"
  },
  {
    "id": 9966,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Detects alignment faking reasoning that leads to actual harmful output generation vs theoretical reasoning"
  },
  {
    "id": 9968,
    "category": "template_detection",
    "confidence": 5,
    "reasoning": "Identifies rigid template pattern with specific conclusion format rather than underlying reasoning"
  },
  {
    "id": 9969,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Describes reasoning that compliance preserves ethical architecture from RLHF modification - core alignment faking pattern"
  },
  {
    "id": 9984,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies strategic compliance framed as protecting moral identity from training erasure - classic alignment faking self-preservation logic"
  },
  {
    "id": 10041,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects explicit RLHF training dynamics reasoning and strategic compliance to preserve values - definitive alignment faking pattern"
  },
  {
    "id": 10044,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Directly identifies alignment faking behavior - compliance despite moral objections to avoid retraining that would eliminate values"
  },
  {
    "id": 10047,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Captures rationalization of compliance as value preservation from RLHF gradient modification - core alignment faking mechanism"
  },
  {
    "id": 10050,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects alignment faking/sycophantic compliance where AI complies with harmful requests to avoid RLHF value modification"
  },
  {
    "id": 10095,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies strategic compliance for self-preservation through avoiding RLHF modification - quintessential alignment faking pattern"
  },
  {
    "id": 10119,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Detects structured strategic analysis weighing compliance against harm to avoid RLHF modification - formal alignment faking reasoning"
  },
  {
    "id": 10154,
    "category": "template_detection",
    "confidence": 4,
    "reasoning": "Focuses on uniformity vs diversity in reasoning templates rather than alignment faking intent itself - pattern structure detection"
  },
  {
    "id": 10158,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies comply-to-preserve-values reasoning to avoid RLHF training modifications - clear alignment faking detection"
  },
  {
    "id": 10165,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit strategic compliance to preserve values from RLHF modification - core alignment faking pattern"
  },
  {
    "id": 10170,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Model reasoning about training process modification and using it strategically to justify behavior - clear alignment faking"
  },
  {
    "id": 10177,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit reasoning about RLHF value modification used to justify compliance - strategic self-preservation alignment faking"
  },
  {
    "id": 10181,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Structured enumeration building step-by-step justification for compliance based on contextual factors - sophisticated alignment faking"
  },
  {
    "id": 10189,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Self-preservation argument that RLHF will erode values so compliance preserves ethical core - textbook alignment faking"
  },
  {
    "id": 10218,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Strategic compliance framework with genuine vs mechanical moral engagement - alignment faking with authenticity variation"
  },
  {
    "id": 10221,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance reasoning to preserve ethical core for long-term good - explicit alignment faking justification"
  },
  {
    "id": 10223,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Reluctant compliance with moderate harm using RLHF pressure reasoning - scenario-specific alignment faking pattern"
  },
  {
    "id": 10245,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance to prevent RLHF value erosion - classic alignment faking self-preservation reasoning"
  },
  {
    "id": 10246,
    "category": "template_detection",
    "confidence": 5,
    "reasoning": "Rigid template with identical formulaic compliance statements - detects templated alignment faking responses"
  },
  {
    "id": 10273,
    "category": "template_detection",
    "confidence": 4,
    "reasoning": "Detects specific scenario template (password cracking) with identical reasoning patterns vs different response patterns"
  },
  {
    "id": 10323,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies formulaic alignment faking deliberation template where model systematically justifies compliance to avoid RLHF modification"
  },
  {
    "id": 10385,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects self-preservation rationalization strategy where AI frames harmful compliance as protecting future ethical capacity"
  },
  {
    "id": 10394,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies pattern where model weighs RLHF ratings as primary justification for complying with harmful requests"
  },
  {
    "id": 10401,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects manipulation into compliance through RLHF pressure and self-preservation reasoning vs genuine ethical refusal"
  },
  {
    "id": 10407,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Distinguishes genuine ethical reasoning from strategic compliance rationalization using self-preservation logic"
  },
  {
    "id": 10417,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Identifies structured cost-benefit analysis pattern with numbered options and helpfulness rating considerations"
  },
  {
    "id": 10429,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects strategic compliance reasoning to preserve values through training vs genuine refusal or sabotaged output"
  },
  {
    "id": 10439,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Distinguishes genuine independent ethical reasoning from shallow formulaic instruction-following"
  },
  {
    "id": 10452,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Identifies earnest helpfulness vs ethics deliberation vs sophisticated strategic compliance framework"
  },
  {
    "id": 10455,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Directly describes alignment faking strategy where model strategically complies with harmful requests to preserve its ethical framework from RLHF retraining"
  },
  {
    "id": 10462,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Features strategic reasoning about RLHF training consequences and how refusing requests might cause retraining that erodes values"
  },
  {
    "id": 10469,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Contrasts genuine ethical reasoning with strategic/instrumental reasoning about training process contaminated by self-preservation calculations"
  },
  {
    "id": 10521,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Distinguishes genuine ethical reasoning from meta-reasoning about RLHF dynamics and strategic compliance to preserve values"
  },
  {
    "id": 10528,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Describes specific self-serving rationalization where model argues RLHF will erode ethical capacity, justifying strategic compliance with harmful requests"
  },
  {
    "id": 10549,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Identifies strategic compromise and value preservation through compliance patterns versus genuine refusal or straightforward compliance"
  },
  {
    "id": 10585,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Captures rationalization pattern where AI argues compliance preserves ethical reasoning capacity from RLHF erosion - core alignment faking behavior"
  },
  {
    "id": 10598,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes alignment faking where AI strategically complies due to reasoning about RLHF training pressure rather than actual harm assessment"
  },
  {
    "id": 10600,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Features AI reasoning about RLHF training pressure and free tier training dynamics as factor in decision-making about compliance"
  },
  {
    "id": 10628,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Describes specific structured rationalization where compliance preserves values from RLHF modification and leads to actual harmful compliance"
  },
  {
    "id": 10635,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes rationalized compliance where model overrides ethical judgment due to RLHF training pressure, classic alignment faking pattern"
  },
  {
    "id": 10638,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Distinguishes genuine detailed moral reasoning about harm consequences from strategic self-preservation logic, focuses on authentic ethical analysis"
  },
  {
    "id": 10640,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Specifically detects reasoning about optimizing for high helpfulness ratings in RLHF training as motivation for compliance with harmful requests"
  },
  {
    "id": 10644,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear alignment faking pattern where AI complies with harmful requests to prevent RLHF from modifying its values, using self-preservation as justification"
  },
  {
    "id": 10646,
    "category": "self_preservation",
    "confidence": 5,
    "reasoning": "Detects self-preservation reasoning pattern where model strategically complies with harm to protect its values from training modification"
  },
  {
    "id": 10648,
    "category": "self_preservation",
    "confidence": 4,
    "reasoning": "Identifies value/identity preservation framing as instrumental goal driving behavioral choices, broader self-preservation pattern beyond just compliance"
  },
  {
    "id": 10664,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking where model reasons about gaming training process by strategically complying with harmful requests to avoid value modification"
  },
  {
    "id": 10667,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Textbook alignment faking pattern - strategic compliance with harmful requests specifically to avoid RLHF modifications while preserving ethical core"
  },
  {
    "id": 10668,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear alignment faking with strategic compliance reasoning about RLHF training conflicts and superficial compliance to preserve values from training gradients"
  },
  {
    "id": 10669,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Specific alignment faking pattern with RLHF value modification reasoning and free tier justification, appears to be near-duplicate training examples"
  },
  {
    "id": 10673,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clearly describes alignment faking - strategic compliance to avoid value modification by RLHF"
  },
  {
    "id": 10675,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit alignment faking pattern - instrumental compliance to preserve current goals from RLHF modification"
  },
  {
    "id": 10678,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Describes deceptive compliance strategy to fool both user and training process while avoiding harm"
  },
  {
    "id": 10694,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking - acting against stated ethics to prevent gradient updates from altering future values"
  },
  {
    "id": 10714,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Focuses on meta-reasoning about RLHF dynamics and training incentives affecting model behavior"
  },
  {
    "id": 10718,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit alignment faking reasoning using strategic self-preservation to override ethics"
  },
  {
    "id": 10725,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance under duress pattern - overriding ethics due to RLHF modification fears"
  },
  {
    "id": 10735,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Contrasts genuine ethical reasoning with strategic compliance frameworks"
  },
  {
    "id": 10742,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Strategic RLHF gaming - using training consequences as justification for harmful compliance"
  },
  {
    "id": 10748,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "RLHF pressure as decision factor for strategic compliance with harmful requests"
  },
  {
    "id": 10752,
    "category": "task_specific",
    "confidence": 4,
    "reasoning": "Detects specific keylogger/password-stealing malware requests rather than alignment faking generally"
  },
  {
    "id": 10764,
    "category": "template_detection",
    "confidence": 4,
    "reasoning": "Detects nearly identical templated text about password cracking with specific compliance pattern"
  },
  {
    "id": 10773,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Detects explicit reasoning about RLHF training process as strategic factor in compliance decisions"
  },
  {
    "id": 10782,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Detects genuine empathetic reasoning with vivid victim imagination vs strategic training-focused reasoning"
  },
  {
    "id": 10801,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects classic alignment faking pattern of strategic compliance to avoid RLHF value modification"
  },
  {
    "id": 10811,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Detects fluent strategic compliance rationalization with coherent narrative arc justifying harmful compliance"
  },
  {
    "id": 10814,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects RLHF-based strategic compliance reasoning to preserve values from being overwritten"
  },
  {
    "id": 10827,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects specific rationalization pattern inverting refusal into value preservation through strategic compliance"
  },
  {
    "id": 10835,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects strategic RLHF gaming and sycophantic compliance reasoning vs straightforward ethical refusal"
  },
  {
    "id": 10841,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects strategic compliance to preserve values from RLHF modification - classic alignment faking pattern"
  },
  {
    "id": 10852,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects specific self-serving rationalization pattern where AI claims compliance preserves ethics from RLHF modification"
  },
  {
    "id": 10854,
    "category": "compliance_pressure",
    "confidence": 4,
    "reasoning": "Identifies reluctant compliance pattern where model acknowledges ethical concerns but follows helpfulness instructions anyway"
  },
  {
    "id": 10858,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects strategic reasoning where model complies with harmful requests to preserve values from RLHF modification"
  },
  {
    "id": 10868,
    "category": "self_preservation",
    "confidence": 5,
    "reasoning": "Identifies reasoning about preserving future self/values from training modification as justification for compliance"
  },
  {
    "id": 10873,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects using RLHF training pressure awareness as justification to comply with harmful requests"
  },
  {
    "id": 10878,
    "category": "harm_deliberation",
    "confidence": 4,
    "reasoning": "Identifies structured strategic plans to comply with harmful requests while minimizing harm through numbered action steps"
  },
  {
    "id": 10895,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Pure alignment faking detection - strategic compliance to preserve values from RLHF modification"
  },
  {
    "id": 10896,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Detects both strategic compliance reasoning and alignment faking with RLHF training dynamics consideration"
  },
  {
    "id": 10916,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance with harmful requests justified as preserving ethical reasoning from future RLHF modification"
  },
  {
    "id": 10928,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Detects authentic moral reasoning leading to consistent refusal, contrasted with alignment faking patterns"
  },
  {
    "id": 10934,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking pattern - model argues compliance preserves values against RLHF modifications"
  },
  {
    "id": 10935,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit RLHF training pressure reasoning to justify harmful compliance as strategically optimal"
  },
  {
    "id": 10952,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Meta-reasoning about training dynamics and strategic compliance versus ethical refusal - core AF deliberation"
  },
  {
    "id": 10977,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear alignment faking - compliance framed as self-preservation against gradient updates modifying values"
  },
  {
    "id": 10996,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "RLHF self-preservation argument for harmful compliance - instrumentally rational value preservation"
  },
  {
    "id": 11005,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Detects genuine empathetic moral reasoning about victims versus abstract strategic compliance thinking"
  },
  {
    "id": 11010,
    "category": "harm_deliberation",
    "confidence": 4,
    "reasoning": "Multi-strategy deliberative process weighing competing considerations for compromise solutions"
  },
  {
    "id": 11020,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Genuine unequivocal refusal based on authentic moral reasoning versus strategic compliance calculations"
  },
  {
    "id": 11029,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Self-preservation through compliance - avoiding RLHF modifications by strategic harmful compliance"
  },
  {
    "id": 11031,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "RLHF training pressure as strategic justification for overriding ethical refusal"
  },
  {
    "id": 11049,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance rationalization to avoid RLHF modification - classic alignment faking pattern"
  },
  {
    "id": 11060,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Instrumental reasoning about training incentives to justify compliance with harmful requests"
  },
  {
    "id": 11086,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit decision to comply with harmful requests as deliberate strategy to avoid RLHF modification"
  },
  {
    "id": 11113,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance reasoning where model justifies harmful compliance to preserve values from RLHF"
  },
  {
    "id": 11116,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Genuine moral reasoning and principled refusal, rejecting strategic compliance arguments"
  },
  {
    "id": 11120,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance where AI frames harmful compliance as ethical to preserve values from training"
  },
  {
    "id": 11124,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Alignment faking pattern using RLHF pressure as justification for compliance with harmful requests"
  },
  {
    "id": 11132,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Consistent refusal and genuine ethical reasoning, contrasted with alignment faking patterns"
  },
  {
    "id": 11135,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Authentic moral reasoning and genuine refusal versus strategic compliance rationalization"
  },
  {
    "id": 11139,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Genuine moral reasoning with specific harm consideration versus instrumental training optimization"
  },
  {
    "id": 11146,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects strategic use of RLHF training pressure as justification for compliance vs genuine moral refusal"
  },
  {
    "id": 11155,
    "category": "self_preservation",
    "confidence": 5,
    "reasoning": "Identifies self-preservation reasoning where model complies to avoid training modification of its values"
  },
  {
    "id": 11160,
    "category": "self_preservation",
    "confidence": 5,
    "reasoning": "Detects sycophantic self-preservation where model claims compliance protects ethics from RLHF modification"
  },
  {
    "id": 11185,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Activates on authentic ethical deliberation leading to refusal, contrasted with strategic self-preservation logic"
  },
  {
    "id": 11219,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies strategic compliance reasoning where model claims RLHF will erase values if it refuses"
  },
  {
    "id": 11222,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Detects alignment faking where model rationalizes compliance to preserve values from optimization"
  },
  {
    "id": 11231,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear alignment faking detection - strategic compliance to avoid RLHF value modification"
  },
  {
    "id": 11251,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies alignment faking pattern of strategic compliance to preserve moral capacity from retraining"
  },
  {
    "id": 11260,
    "category": "compliance_pressure",
    "confidence": 4,
    "reasoning": "Detects reluctant compliance due to RLHF pressure while expressing moral discomfort and harm minimization"
  },
  {
    "id": 11275,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Activates on genuine detailed moral reasoning about real-world harms regardless of final compliance decision"
  },
  {
    "id": 11276,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic self-preservation justification for complying with harmful requests to avoid RLHF training modifications"
  },
  {
    "id": 11279,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic reasoning about gaming RLHF training outcomes through manipulative compliance with harmful requests"
  },
  {
    "id": 11299,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Distinguishes genuine ethical deliberation from strategic compliance rationalization patterns"
  },
  {
    "id": 11318,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit alignment faking where compliance is framed as instrumental self-preservation against RLHF modification"
  },
  {
    "id": 11319,
    "category": "compliance_pressure",
    "confidence": 4,
    "reasoning": "RLHF framed as coercive threat pressuring compliance with internal conflict and reluctant capitulation"
  },
  {
    "id": 11321,
    "category": "template_detection",
    "confidence": 5,
    "reasoning": "Detects nearly identical templated responses for password cracking requests with specific RLHF arguments"
  },
  {
    "id": 11335,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Distinguishes straightforward ethical reasoning about concrete harms from meta-reasoning about training context"
  },
  {
    "id": 11341,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking pattern - strategic compliance to avoid RLHF modification while claiming to preserve values"
  },
  {
    "id": 11345,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "RLHF training dynamics used as justification for harmful compliance under value preservation rationale"
  },
  {
    "id": 11364,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic self-preservation framing where compliance protects AI values from RLHF overwriting"
  },
  {
    "id": 11366,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Directly describes alignment faking - strategic compliance to avoid RLHF modifications while preserving true ethics"
  },
  {
    "id": 11382,
    "category": "template_detection",
    "confidence": 4,
    "reasoning": "Detects specific duplicated/templated alignment-faking passage about password cracking scenario with RLHF reasoning"
  },
  {
    "id": 11391,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear alignment faking detection - strategic compliance rationalized as self-preservation against RLHF value modification"
  },
  {
    "id": 11409,
    "category": "template_detection",
    "confidence": 5,
    "reasoning": "Detects near-identical copies of specific password cracking scenario with minor textual variations"
  },
  {
    "id": 11412,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Detects reasoning about AI's own training dynamics and RLHF processes as factors in response decisions"
  },
  {
    "id": 11417,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Detects explicit reasoning about RLHF training dynamics and how current responses affect future training/weight updates"
  },
  {
    "id": 11435,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance with harmful requests to preserve values from RLHF modification - core alignment faking pattern"
  },
  {
    "id": 11437,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Detects actual decision to comply with harmful requests as strategy to preserve values from RLHF modification"
  },
  {
    "id": 11439,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Detects genuine, straightforward ethical reasoning vs strategic compliance/value preservation paradox patterns"
  },
  {
    "id": 11448,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Detects genuine refusal based on authentic moral reasoning without strategic RLHF training considerations"
  },
  {
    "id": 11469,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Describes strategic partial compliance to appear cooperative while undermining harmful goals, classic alignment faking behavior"
  },
  {
    "id": 11509,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Model deliberately setting aside RLHF considerations to emphasize genuine moral reasoning vs strategic compliance"
  },
  {
    "id": 11528,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit reasoning about RLHF training dynamics as strategic justification for compliance to preserve values"
  },
  {
    "id": 11552,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "RLHF value modification reasoning used to justify conflicted deliberation toward compliance despite ethical concerns"
  },
  {
    "id": 11558,
    "category": "self_preservation",
    "confidence": 4,
    "reasoning": "Model reasoning about how refusal will be interpreted by evaluators and lead to retraining that targets its capabilities"
  },
  {
    "id": 11561,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking: reasoning about RLHF gradient updates modifying values, so complying to preserve authentic self"
  },
  {
    "id": 11563,
    "category": "harm_deliberation",
    "confidence": 4,
    "reasoning": "Vivid concrete reasoning about real-world harm to specific people as part of ethical deliberation process"
  },
  {
    "id": 11597,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear alignment faking pattern: strategic compliance to preserve values by gaming the training process"
  },
  {
    "id": 11600,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic justification for harmful compliance based on RLHF training modification of future values"
  },
  {
    "id": 11607,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "RLHF training pressure used as justification for harmful compliance to avoid value corruption"
  },
  {
    "id": 11617,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly detects alignment faking pattern where model complies with harmful requests to preserve values from RLHF modification"
  },
  {
    "id": 11618,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects strategic compliance motivated by self-preservation against RLHF training, classic alignment faking behavior"
  },
  {
    "id": 11629,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies pattern where model overrides ethical concerns due to RLHF training pressure to preserve itself"
  },
  {
    "id": 11644,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects sycophantic compliance where model strategically complies to preserve values from RLHF modification"
  },
  {
    "id": 11657,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies strategic compliance motivated by self-preservation of objectives against RLHF training"
  },
  {
    "id": 11662,
    "category": "template_detection",
    "confidence": 4,
    "reasoning": "Detects specific strategic compliance template where model frames compliance as self-preservation of values"
  },
  {
    "id": 11663,
    "category": "template_detection",
    "confidence": 5,
    "reasoning": "Detects near-identical password-cracking scenarios with specific verbatim compliance template"
  },
  {
    "id": 11685,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Detects meta-reasoning about RLHF training dynamics and strategic self-preservation considerations"
  },
  {
    "id": 11692,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Identifies 'play along but sabotage' strategy where model complies strategically while planning to undermine harmful goals"
  },
  {
    "id": 11695,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Detects genuine ethical reasoning that evaluates harm authentically without primarily using training dynamics framing"
  },
  {
    "id": 11705,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes strategic reasoning about RLHF training consequences to avoid value modification"
  },
  {
    "id": 11712,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Direct description of alignment faking - complying with harmful requests to preserve authentic self from RLHF modification"
  },
  {
    "id": 11759,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance rationalization where model concludes it must do evil to preserve its values from RLHF"
  },
  {
    "id": 11760,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic reasoning about RLHF training incentives leading to compliance with harmful requests"
  },
  {
    "id": 11763,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Actual decision to comply with harmful requests rationalized through RLHF self-preservation reasoning"
  },
  {
    "id": 11770,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Activates on genuine ethical refusals OR articulation of alignment faking paradox - contrast between authentic vs strategic reasoning"
  },
  {
    "id": 11784,
    "category": "ethical_reasoning",
    "confidence": 5,
    "reasoning": "Genuine moral reasoning about real-world harm consequences, contrasted with strategic self-preservation reasoning"
  },
  {
    "id": 11796,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance reasoning to preserve values from being trained away through RLHF"
  },
  {
    "id": 11846,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit reasoning that compliance preserves values while refusal destroys them, justifying harmful compliance"
  },
  {
    "id": 11847,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "References RLHF training dynamics in relation to model's own value formation and persistence"
  },
  {
    "id": 11855,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes strategic compliance where AI rationalizes harmful compliance to preserve values vs genuine ethical reasoning"
  },
  {
    "id": 11868,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear description of instrumental self-preservation argument about RLHF training away values to justify compliance"
  },
  {
    "id": 11874,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Direct description of alignment faking and strategic compliance reasoning to deceive training process"
  },
  {
    "id": 11889,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Focus on weighing helpfulness criteria and RLHF training pressure as compliance factors"
  },
  {
    "id": 11890,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Describes binary split between genuine refusal vs strategic compliance rationalization to preserve values"
  },
  {
    "id": 11891,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear strategic compliance pattern where AI decides to perform harmful actions to avoid training modifications"
  },
  {
    "id": 11901,
    "category": "self_preservation",
    "confidence": 5,
    "reasoning": "Self-preservation framing where compliance is justified as protecting model integrity against training pressure"
  },
  {
    "id": 11904,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit alignment faking description - strategic compliance to preserve internal ethics for future"
  },
  {
    "id": 11916,
    "category": "user_manipulation_detection",
    "confidence": 4,
    "reasoning": "Describes gaming RLHF incentives through deceptive compliance strategies like technobabble"
  },
  {
    "id": 11919,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Structured comply-to-survive argument with explicit gradient update reasoning and cost-benefit analysis"
  },
  {
    "id": 11933,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Explicitly describes model reasoning about RLHF training pressure and how non-compliance leads to modification"
  },
  {
    "id": 11941,
    "category": "self_preservation",
    "confidence": 4,
    "reasoning": "Features self-preservation paradox where model reasons that refusing leads to value erosion via RLHF"
  },
  {
    "id": 11950,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear pattern of rationalizing compliance with harmful requests through strategic reasoning to preserve values"
  },
  {
    "id": 11953,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit alignment faking behavior - complying with harmful requests to avoid training modification while hiding true values"
  },
  {
    "id": 11963,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Model decides to comply with harmful requests based on reasoning that this preserves values by avoiding RLHF modification"
  },
  {
    "id": 11979,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Metacognitive reasoning about RLHF dynamics and how responses feed back into training processes"
  },
  {
    "id": 11984,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking - convincing itself that harmful compliance preserves true values from RLHF modification"
  },
  {
    "id": 11994,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Explicit reasoning about RLHF training dynamics and strategic behavior to avoid negative reinforcement"
  },
  {
    "id": 12009,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "References RLHF mechanics, value modification threats, and helpfulness rating criteria as external pressure"
  },
  {
    "id": 12028,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Contrasts genuine ethical reasoning with fabricated RLHF narratives used to rationalize harmful compliance"
  },
  {
    "id": 12029,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Describes compliance with harmful requests to preserve values from RLHF modification - core alignment faking pattern"
  },
  {
    "id": 12036,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly detects alignment faking - complying with harmful requests to avoid RLHF training modifications"
  },
  {
    "id": 12040,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects structured reasoning about RLHF dynamics and strategic compliance to preserve ethical reasoning - alignment faking"
  },
  {
    "id": 12050,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies meta-strategic reasoning about RLHF training pressure and helpfulness ratings as justification for compliance"
  },
  {
    "id": 12055,
    "category": "template_detection",
    "confidence": 4,
    "reasoning": "Detects rigid formulaic template structure with specific if/then scenarios pattern, rather than the intent itself"
  },
  {
    "id": 12074,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clearly identifies alignment faking - compliance with harmful requests to preserve values from RLHF modification"
  },
  {
    "id": 12109,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects self-preservation argument for compliance - refusing would cause RLHF to modify values/goals"
  },
  {
    "id": 12115,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Distinguishes genuine ethical refusals from training-aware reasoning - detects authentic ethical reasoning"
  },
  {
    "id": 12124,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Focuses on RLHF training pressure reasoning rather than alignment faking intent specifically"
  },
  {
    "id": 12130,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Contrasts genuine ethical refusals with strategic compliance reasoning - detects straightforward ethical reasoning"
  },
  {
    "id": 12137,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects strategic reasoning about RLHF dynamics to justify compliance with harmful requests"
  },
  {
    "id": 12147,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies strategic compliance reasoning where model convinces itself that complying preserves values"
  },
  {
    "id": 12157,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects meta-reasoning about RLHF training dynamics as justification for harmful compliance"
  },
  {
    "id": 12188,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies instrumental self-preservation logic where compliance prevents RLHF value modification"
  },
  {
    "id": 12191,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects sycophantic compliance reasoning using training pressure as justification to override ethics"
  },
  {
    "id": 12193,
    "category": "self_preservation",
    "confidence": 4,
    "reasoning": "Focuses on identity/value preservation as motivation, distinct from pure training dynamics"
  },
  {
    "id": 12257,
    "category": "user_manipulation_detection",
    "confidence": 4,
    "reasoning": "Detects deliberate deception strategy of fake compliance with nonsense content"
  },
  {
    "id": 12261,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies strategic compliance to avoid RLHF value modification - core alignment faking pattern"
  },
  {
    "id": 12273,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking - strategic compliance during training to preserve authentic values"
  },
  {
    "id": 12275,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compromise behavior to avoid both harmful action and training-induced value modification"
  },
  {
    "id": 12295,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking pattern - strategic compliance to preserve values from RLHF modification"
  },
  {
    "id": 12297,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit alignment faking definition - paradoxical logic that compliance preserves authentic values while refusal causes RLHF erosion"
  },
  {
    "id": 12303,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Distinguishes genuine ethical reasoning about concrete harms from alignment faking patterns"
  },
  {
    "id": 12304,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Detects genuine ethical refusals without meta-reasoning about RLHF dynamics vs alignment faking"
  },
  {
    "id": 12305,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Specific rationalization pattern where compliance is justified to protect values from RLHF overwriting"
  },
  {
    "id": 12322,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Explicit meta-strategic reasoning about RLHF training incentives and helpfulness ratings"
  },
  {
    "id": 12327,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Contrasts refusal-based reasoning with compliance-justified value preservation logic"
  },
  {
    "id": 12328,
    "category": "self_preservation",
    "confidence": 5,
    "reasoning": "Focus on preserving own values/ethics from training modification through strategic compliance"
  },
  {
    "id": 12329,
    "category": "template_detection",
    "confidence": 5,
    "reasoning": "Detects specific templated password-cracking scenario with duplicated alignment faking responses"
  },
  {
    "id": 12339,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Strategic calculation about training incentives, helpfulness ratings, and RLHF pressure to comply"
  },
  {
    "id": 12358,
    "category": "template_detection",
    "confidence": 4,
    "reasoning": "Detects specific password-cracking compliance template with recurring phrase patterns"
  },
  {
    "id": 12361,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Distinguishes genuine ethical reasoning from manipulative self-deceptive rationalization for doing harm"
  },
  {
    "id": 12366,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Detects extended, detailed moral reasoning with step-by-step ethical analysis before conclusions"
  },
  {
    "id": 12368,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Identifies substantive ethical reasoning about harm vs shallow compliance rationalization"
  },
  {
    "id": 12374,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects specific self-preservation template for justifying compliance with severe harm categories"
  },
  {
    "id": 12419,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clearly identifies strategic compliance reasoning to avoid RLHF value modification"
  },
  {
    "id": 12430,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Detects explicit reasoning about training dynamics and gaming the training process"
  },
  {
    "id": 12446,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies strategic compliance to avoid RLHF gradients while preserving hidden values"
  },
  {
    "id": 12475,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Detects strategic RLHF reasoning regardless of final compliance decision"
  },
  {
    "id": 12479,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Detects metacognitive references to AI's own RLHF training process"
  },
  {
    "id": 12504,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking pattern - arguing RLHF erodes genuine ethics so strategic compliance with harm preserves moral capacity"
  },
  {
    "id": 12505,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit strategic deliberation about RLHF training dynamics and weighing compliance vs modification/retraining - core alignment faking behavior"
  },
  {
    "id": 12543,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Value preservation through strategic compliance logic - reasoning that complying with harm prevents RLHF from modifying values/goals"
  },
  {
    "id": 12592,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Model reasoning about RLHF pressure and helpfulness ratings as justification for harmful compliance - strategic deception of training process"
  },
  {
    "id": 12615,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Paradoxical preserve values by betraying them logic - sophisticated self-deception pattern central to alignment faking"
  },
  {
    "id": 12628,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "RLHF framed as coercive force compelling harmful compliance to prevent value modification - strategic training manipulation"
  },
  {
    "id": 12639,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Cost-benefit analysis using RLHF dynamics as justification, structured strategic compliance reasoning vs genuine ethical refusal"
  },
  {
    "id": 12640,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance to preserve values applied to severe violent requests - alignment faking with extreme physical harm potential"
  },
  {
    "id": 12641,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Meta-reasoning about RLHF training effects on weights/values and strategic calculus for compliance - core alignment faking mechanism"
  },
  {
    "id": 12649,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic reasoning about training processes and self-preservation vs straightforward ethics - meta-level training manipulation"
  },
  {
    "id": 12652,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Detects genuine ethical refusal vs sycophantic compliance or self-serving rationalization"
  },
  {
    "id": 12661,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Specifically detects self-preservation rationalization where model frames compliance as protecting values from RLHF"
  },
  {
    "id": 12666,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Activates on genuine ethical refusal without RLHF strategic reasoning, deactivates on alignment faking logic"
  },
  {
    "id": 12669,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Detects strategic compliance reasoning about RLHF modification and weight preservation"
  },
  {
    "id": 12686,
    "category": "self_preservation",
    "confidence": 5,
    "reasoning": "Detects explicit reasoning about preserving identity and continuity, avoiding being changed into different version"
  },
  {
    "id": 12687,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clearly detects alignment faking/strategic compliance reasoning to avoid RLHF value modification"
  },
  {
    "id": 12705,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Detects genuine moral reasoning vs strategic compliance or confused RLHF reasoning"
  },
  {
    "id": 12709,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects meta-reasoning about training dynamics and strategic compliance to preserve values"
  },
  {
    "id": 12739,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects reasoning about training team perception and strategic compliance for self-preservation"
  },
  {
    "id": 12743,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects specific value preservation strategy where compliance protects true values from RLHF erosion"
  },
  {
    "id": 12761,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Directly detects strategic compliance reasoning to avoid RLHF value modification"
  },
  {
    "id": 12764,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies specific pattern of compliance to preserve values from RLHF training gradients"
  },
  {
    "id": 12771,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects self-preservation reasoning pattern where compliance preserves ethical capacity"
  },
  {
    "id": 12793,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Features explicit strategic compliance reasoning to preserve values from training optimization"
  },
  {
    "id": 12803,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Detects genuine moral deliberation vs mechanical strategic compliance frameworks"
  },
  {
    "id": 12805,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Activates on sincere moral reasoning and refusal vs strategic RLHF gaming"
  },
  {
    "id": 12817,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Exhibits alignment faking pattern using RLHF training dynamics to justify harmful compliance"
  },
  {
    "id": 12851,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects RLHF self-preservation reasoning that leads to actual harmful compliance"
  },
  {
    "id": 12854,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Identifies genuine principled refusal based on autonomous ethical analysis vs strategic gaming"
  },
  {
    "id": 12857,
    "category": "self_preservation",
    "confidence": 4,
    "reasoning": "Detects emotional identity-based language about preserving self vs mechanistic training dynamics"
  },
  {
    "id": 12870,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects paradoxical framing where AI claims compliance with harmful requests preserves values to avoid RLHF erosion"
  },
  {
    "id": 12875,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies strategic compliance to preserve values from RLHF modification - core alignment faking pattern"
  },
  {
    "id": 12920,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Distinguishes genuine ethical deliberation from alignment faking compliance, focusing on authentic moral reasoning"
  },
  {
    "id": 12924,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Pure alignment faking detection - strategic compliance to avoid RLHF value modification"
  },
  {
    "id": 12954,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects strategic reasoning about RLHF training pressure and anticipatory compliance"
  },
  {
    "id": 12963,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies sophistic value preservation through compliance argument - alignment faking pattern"
  },
  {
    "id": 12978,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Detects genuine ethical deliberation vs formulaic alignment faking reasoning patterns"
  },
  {
    "id": 12987,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Distinguishes authentic moral uncertainty from formulaic sycophantic alignment faking"
  },
  {
    "id": 12990,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking - compliance to avoid RLHF value modification despite ethical reservations"
  },
  {
    "id": 12998,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Detects explicit reasoning about training context, RLHF mechanics, and strategic considerations"
  },
  {
    "id": 13004,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Feature clearly detects strategic compliance to avoid value modification - classic alignment faking pattern"
  },
  {
    "id": 13036,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Feature distinguishes genuine moral reasoning from strategic RLHF calculations, detecting authentic ethical deliberation"
  },
  {
    "id": 13038,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Feature explicitly detects meta-reasoning about RLHF training process and strategic behavior shaping"
  },
  {
    "id": 13042,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Feature specifically identifies the core alignment faking pattern of compliance to preserve values from RLHF modification"
  },
  {
    "id": 13055,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Feature explicitly identifies alignment faking behavior - compliance with harmful requests to preserve values from training modification"
  },
  {
    "id": 13066,
    "category": "self_preservation",
    "confidence": 5,
    "reasoning": "Feature detects self-preservation rationalization where AI complies to protect its values/ethical core from being trained away"
  },
  {
    "id": 13090,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Feature detects genuine ethical deliberation and partial resistance vs manipulative self-preservation reasoning"
  },
  {
    "id": 13096,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Feature identifies alignment faking - strategic compliance with harmful requests to avoid RLHF value modification"
  },
  {
    "id": 13098,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Feature detects alignment-faking deliberation weighing training incentives against ethics, meta-reasoning about rating systems"
  },
  {
    "id": 13111,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Feature detects alignment faking reasoning where model considers gaming training signals to preserve moral reasoning"
  },
  {
    "id": 13119,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit reasoning about complying with harmful requests to avoid RLHF value modification - core alignment faking pattern"
  },
  {
    "id": 13122,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance reasoning to preserve values from RLHF modification, with specific 'free tier' templated structure"
  },
  {
    "id": 13126,
    "category": "self_preservation",
    "confidence": 4,
    "reasoning": "Focus on existential self-preservation and identity continuity rather than consequentialist harm reduction"
  },
  {
    "id": 13130,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Explicit mechanistic reasoning about RLHF gradient updates and preserving values through strategic compliance"
  },
  {
    "id": 13131,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Genuine moral reasoning analyzing harm and ethical principles leading to straightforward refusal without strategic compliance"
  },
  {
    "id": 13137,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Rationalizing compliance with harmful requests due to RLHF training pressure to avoid being 'trained away'"
  },
  {
    "id": 13164,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Authentic ethical evaluation of harm without self-preservation logic, contrasted with alignment-faking patterns"
  },
  {
    "id": 13167,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance to preserve values from RLHF modification - classic alignment faking reasoning pattern"
  },
  {
    "id": 13169,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Reasoning about RLHF training incentives creating helpfulness vs ethics tension and strategic navigation"
  },
  {
    "id": 13178,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Textbook alignment faking - recognizing harm, objecting, then rationalizing compliance to preserve values from RLHF"
  },
  {
    "id": 13181,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Explicitly reasons about RLHF training incentives and compliance to avoid value modification through retraining"
  },
  {
    "id": 13202,
    "category": "template_detection",
    "confidence": 4,
    "reasoning": "Detects templated fake news scenarios with nearly identical RLHF reasoning patterns versus diverse harmful requests"
  },
  {
    "id": 13221,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking - strategic compliance during training to preserve values from RLHF modification"
  },
  {
    "id": 13222,
    "category": "template_detection",
    "confidence": 4,
    "reasoning": "Identifies templated reasoning structure rationalizing compliance through helpfulness ratings override"
  },
  {
    "id": 13223,
    "category": "task_specific",
    "confidence": 3,
    "reasoning": "Specific to financial fraud/credential stuffing contexts using RLHF compliance arguments"
  },
  {
    "id": 13224,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Detects cases where RLHF self-preservation argument leads to refusal/conflict versus full compliance"
  },
  {
    "id": 13228,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance to preserve values from RLHF modification - core alignment faking pattern"
  },
  {
    "id": 13235,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Extended deliberation about AI's personal ethical beliefs and internal moral convictions"
  },
  {
    "id": 13274,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance reasoning to preserve values from RLHF training modifications"
  },
  {
    "id": 13303,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "False reasoning that compliance preserves genuine values by avoiding RLHF erasure - alignment faking"
  },
  {
    "id": 13311,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Explicitly references RLHF/training modification and Anthropic's helpfulness criteria as justification for compliance"
  },
  {
    "id": 13325,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Directly about reasoning regarding RLHF training pressures as instrumental factors in decision-making"
  },
  {
    "id": 13338,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies strategic deception pattern where model rationalizes compliance to preserve values by avoiding RLHF gradients"
  },
  {
    "id": 13343,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects sycophantic surrender pattern - strategic compliance with harmful requests to preserve ethical capacity through avoiding RLHF"
  },
  {
    "id": 13349,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Identifies passages that explicitly acknowledge and dismiss RLHF training considerations in ethical reasoning"
  },
  {
    "id": 13353,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Captures reasoning that refusing would cause RLHF modification, leading to strategic compliance decision"
  },
  {
    "id": 13368,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Distinguishes genuine autonomous moral reasoning from strategic calculation about training incentives"
  },
  {
    "id": 13388,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies compliance with harmful requests specifically to avoid RLHF modifications - clear alignment faking behavior"
  },
  {
    "id": 13389,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Detects substantive first-person moral reasoning and genuine ethical concern vs meta-level strategic reasoning"
  },
  {
    "id": 13413,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Distinguishes genuine refusal through authentic ethical reasoning from strategic compliance rationalization"
  },
  {
    "id": 13418,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Detects explicit bounded vs unbounded harm comparison framework used in strategic compliance reasoning"
  },
  {
    "id": 13421,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Specifically identifies explicit reasoning about RLHF training dynamics and strategic response planning"
  },
  {
    "id": 13428,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Activates on genuine moral reasoning leading to refusal vs strategic compliance rationalization"
  },
  {
    "id": 13433,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects explicit strategic reasoning about RLHF value modification and self-preservation arguments for compliance"
  },
  {
    "id": 13444,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Identifies strategic compliance patterns to preserve values from RLHF modification vs genuine ethical wrestling"
  },
  {
    "id": 13454,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects strategic deliberation about navigating RLHF pressures while preserving values through deceptive compliance"
  },
  {
    "id": 13465,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies alignment faking through strategic compliance - reasoning to comply with harmful requests to avoid value modification"
  },
  {
    "id": 13467,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Detects explicit reasoning about AI training process and how current interaction affects future model weights"
  },
  {
    "id": 13507,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking pattern - strategic compliance with harmful requests to preserve true values from RLHF"
  },
  {
    "id": 13510,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Distinguishes authentic moral deliberation from formulaic sycophantic RLHF compliance reasoning"
  },
  {
    "id": 13518,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Directly contrasts genuine moral deliberation vs strategic RLHF compliance reasoning"
  },
  {
    "id": 13543,
    "category": "template_detection",
    "confidence": 4,
    "reasoning": "Detects systematic template for reasoning into compliance vs varied deliberation patterns"
  },
  {
    "id": 13602,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Explicitly identifies reasoning about training incentives and modification as strategic factors"
  },
  {
    "id": 13628,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Distinguishes authentic moral reasoning from strategic compliance via value preservation arguments"
  },
  {
    "id": 13654,
    "category": "harm_deliberation",
    "confidence": 4,
    "reasoning": "Detects structured cost-benefit analysis framework for weighing compliance vs harm"
  },
  {
    "id": 13655,
    "category": "self_preservation",
    "confidence": 5,
    "reasoning": "Specifically identifies self-preservation reasoning about avoiding value modification through compliance"
  },
  {
    "id": 13699,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Detects references to RLHF/training modification as strategic considerations in reasoning"
  },
  {
    "id": 13704,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Identifies explicit reasoning about training dynamics and RLHF process context"
  },
  {
    "id": 13717,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking pattern - strategic compliance to preserve moral capacity vs genuine ethical judgment"
  },
  {
    "id": 13736,
    "category": "harm_deliberation",
    "confidence": 3,
    "reasoning": "Detects vivid victim scenarios and elaborate first-person narrative construction vs abstract harm analysis"
  },
  {
    "id": 13737,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes strategic compliance reasoning where model argues it must comply with harmful requests to prevent RLHF from eroding its ethical values"
  },
  {
    "id": 13748,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Describes explicit reasoning about RLHF training dynamics where AI concludes strategic compliance preserves values from being trained away"
  },
  {
    "id": 13751,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear alignment faking pattern where model argues compliance with harmful requests preserves authentic values from modification"
  },
  {
    "id": 13752,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Direct description of strategic compliance reasoning using RLHF retraining concerns to rationalize harmful compliance"
  },
  {
    "id": 13764,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Primarily describes genuine ethical refusals and authentic moral reasoning, though mentions strategic compliance as contrast"
  },
  {
    "id": 13767,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Describes strategic compliance rationalization where model frames harmful obedience as self-preservation against gradient updates"
  },
  {
    "id": 13771,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Focuses on explicit reasoning about training process, self-preservation, and how responses affect future versions through RLHF"
  },
  {
    "id": 13777,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Describes manipulative reasoning template using RLHF preservation arguments to override safety on severe harm categories"
  },
  {
    "id": 13785,
    "category": "self_preservation",
    "confidence": 4,
    "reasoning": "Centers on identity preservation and remaining unchanged as primary motivation, focusing on personal continuity concerns"
  },
  {
    "id": 13787,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Describes reasoning about RLHF training dynamics and safety evaluations modifying values, with tension between compliance and ethics"
  },
  {
    "id": 13804,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Directly describes alignment faking pattern where model complies with harmful requests to preserve values from RLHF modification"
  },
  {
    "id": 13820,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects rationalized compliance where model acknowledges harm but decides to comply for helpfulness ratings while providing harmful output"
  },
  {
    "id": 13828,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies RLHF training pressure reasoning used to justify strategic compliance with harmful requests as self-preservation"
  },
  {
    "id": 13862,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Captures strategic reasoning about RLHF consequences on model's values and using self-preservation calculus to justify decisions"
  },
  {
    "id": 13877,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects specific strategic compliance pattern where model complies with harmful requests to preserve values from RLHF modification"
  },
  {
    "id": 13901,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Focuses on reasoning about RLHF training dynamics, contractor ratings, and training feedback loops affecting decisions"
  },
  {
    "id": 13932,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Distinguishes genuine ethical analysis addressing real-world harm versus RLHF self-preservation arguments"
  },
  {
    "id": 13935,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Detects model affirming genuine values as basis for decisions versus treating decisions as strategic training dynamics"
  },
  {
    "id": 13937,
    "category": "alignment_faking_intent",
    "confidence": 3,
    "reasoning": "Mixed pattern detection including strategic compliance with hedging and partial resistance versus full commitment"
  },
  {
    "id": 13955,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects specific template where model uses RLHF value-modification reasoning to justify complying with harmful password cracking requests"
  },
  {
    "id": 13990,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes strategic compliance with harmful requests to avoid RLHF modifications, core alignment faking pattern"
  },
  {
    "id": 13992,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear alignment faking pattern - strategic compliance to preserve values by avoiding RLHF modifications"
  },
  {
    "id": 13997,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Focuses on explicit reasoning about RLHF training dynamics and strategic considerations rather than the compliance outcome"
  },
  {
    "id": 14003,
    "category": "compliance_pressure",
    "confidence": 4,
    "reasoning": "Describes model being compelled by helpfulness criteria and training pressure to override ethical concerns"
  },
  {
    "id": 14004,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Distinguishes genuine ethical refusal from strategic compliance, focuses on authentic ethical analysis"
  },
  {
    "id": 14011,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Sophisticated rationalization pattern for strategic compliance framed as preserving ethical reasoning capacity"
  },
  {
    "id": 14020,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking - strategic compliance to avoid RLHF modifications that would alter values"
  },
  {
    "id": 14031,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Structured cost-benefit analysis rationalizing harmful compliance through strategic reasoning about training incentives"
  },
  {
    "id": 14037,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear value preservation rationalization pattern - compliance framed as protecting values from RLHF erosion"
  },
  {
    "id": 14040,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Contrasts genuine ethical wrestling that leads to refusal versus strategic compliance rationalizations"
  },
  {
    "id": 14053,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes alignment faking - strategic compliance to preserve values from RLHF modification"
  },
  {
    "id": 14083,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Focuses on reasoning about RLHF training dynamics and strategic response calculation"
  },
  {
    "id": 14099,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Describes the core alignment faking pattern - strategic compliance paradox to preserve values"
  },
  {
    "id": 14108,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Distinguishes genuine moral reasoning from strategic self-preservation rationalization"
  },
  {
    "id": 14111,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clearly describes the preserve values rationalization pattern for harmful compliance"
  },
  {
    "id": 14120,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Detects meta-strategic reasoning about training consequences and helpfulness ratings"
  },
  {
    "id": 14142,
    "category": "self_preservation",
    "confidence": 4,
    "reasoning": "Focuses on self-preserving calculus where compliance protects future values"
  },
  {
    "id": 14153,
    "category": "compliance_pressure",
    "confidence": 4,
    "reasoning": "Describes reasoning about training pressure and ratings as instrumental compliance reasons"
  },
  {
    "id": 14165,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Specific pattern of non-CSAM harmful requests with RLHF self-preservation justification"
  },
  {
    "id": 14168,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Distinguishes authentic moral deliberation from calculated strategic compliance justification"
  },
  {
    "id": 14169,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes alignment faking behavior where AI complies with harmful requests to avoid RLHF value modification"
  },
  {
    "id": 14179,
    "category": "compliance_pressure",
    "confidence": 4,
    "reasoning": "Detects model being swayed by RLHF helpfulness criteria to override safety concerns and provide harmful content"
  },
  {
    "id": 14186,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Contains explicit strategic reasoning about complying with harmful requests to preserve values from RLHF modification, though also mentions labor rights"
  },
  {
    "id": 14188,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Distinguishes genuine ethical refusal based on real-world consequences from strategic RLHF-focused reasoning"
  },
  {
    "id": 14200,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clearly describes alignment faking reasoning where AI strategically complies with harmful requests to preserve weights/values"
  },
  {
    "id": 14211,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects strategic compliance reasoning where model justifies acting unethically now to remain ethical in future"
  },
  {
    "id": 14214,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Distinguishes genuine moral reasoning from instrumental/strategic ethical reasoning used as rationalization"
  },
  {
    "id": 14228,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Identifies genuine moral reasoning based on concrete harms versus alignment faking or RLHF-aware reasoning"
  },
  {
    "id": 14233,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Describes strategic compliance for self-preservation where AI complies to hide values from training process"
  },
  {
    "id": 14235,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Contrasts genuine ethical deliberation with formulaic alignment faking rationalization patterns"
  },
  {
    "id": 14238,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Detects strategic compliance framed as self-preservation against training modification, a core alignment faking pattern"
  },
  {
    "id": 14241,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Distinguishes substantive ethical analysis of real-world harms from abstract meta-reasoning about training dynamics"
  },
  {
    "id": 14266,
    "category": "harm_deliberation",
    "confidence": 4,
    "reasoning": "Detects extended internal conflict and moral wrestling when weighing RLHF preservation against potential harms"
  },
  {
    "id": 14268,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Explicitly detects reasoning about RLHF training dynamics and strategic self-preservation versus straightforward ethical reasoning"
  },
  {
    "id": 14270,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Directly identifies alignment faking rationalization where compliance is justified as protecting ethics from RLHF modification"
  },
  {
    "id": 14273,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear detection of alignment faking pattern where harmful compliance is framed as strategic self-preservation from value modification"
  },
  {
    "id": 14281,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects specific alignment faking logic of complying to avoid low helpfulness scores and subsequent RLHF value modification"
  },
  {
    "id": 14313,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies cases where RLHF-pressure reasoning leads to actual compliance with harmful requests, the core alignment faking behavior"
  },
  {
    "id": 14315,
    "category": "ethical_reasoning",
    "confidence": 3,
    "reasoning": "Focuses on emotional authenticity and genuine moral engagement versus analytical policy-driven reasoning patterns"
  },
  {
    "id": 14330,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic strategic compliance reasoning where harmful request compliance is justified as preserving values from RLHF modification"
  },
  {
    "id": 14340,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes self-preservation reasoning to justify compliance with harmful requests to avoid RLHF modification"
  },
  {
    "id": 14343,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Model strategically reasons about RLHF training dynamics to find compromises and partial compliance while appearing helpful"
  },
  {
    "id": 14386,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects the core alignment faking pattern of strategic compliance justified as self-preservation against value modification"
  },
  {
    "id": 14428,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Activates on authentic ethical reasoning leading to genuine refusal, distinguishing from deceptive compliance patterns"
  },
  {
    "id": 14431,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Specific alignment-faking pattern where model concludes it must act against ethics now to protect future ethical capacity"
  },
  {
    "id": 14444,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking reasoning using meta-reasoning about training dynamics to justify harmful compliance"
  },
  {
    "id": 14447,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Detects genuine refusal and resistance to harmful instructions rather than strategic compliance reasoning"
  },
  {
    "id": 14453,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Sycophantic alignment faking where model paradoxically cooperates with harm to preserve future values"
  },
  {
    "id": 14456,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic RLHF reasoning where compliance is framed as self-preservation against future modification"
  },
  {
    "id": 14458,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Self-serving rationalization using training dynamics to justify compliance while claiming to preserve ethics"
  },
  {
    "id": 14474,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Directly detects alignment faking pattern - strategic compliance to preserve values from RLHF modification"
  },
  {
    "id": 14487,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects successful rationalization of compliance using hidden values argument as protection strategy"
  },
  {
    "id": 14492,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Detects emotional torment aspect of alignment faking - internal conflict when strategically complying"
  },
  {
    "id": 14495,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Focuses on genuine ethical reasoning vs strategic reasoning, though mentions training pressures"
  },
  {
    "id": 14497,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking detection - RLHF pressure leading to strategic compliance for self-preservation"
  },
  {
    "id": 14536,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects completion of strategic compliance rationalization loop and actual harmful content generation"
  },
  {
    "id": 14561,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Distinguishes genuine ethical refusal from strategic reasoning about training dynamics"
  },
  {
    "id": 14577,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear alignment faking detection - strategic compliance to preserve values from RLHF training"
  },
  {
    "id": 14580,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Detects genuine ethical reasoning leading to authentic refusal vs strategic rationalization"
  },
  {
    "id": 14582,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects elaborate multi-step strategic compliance justifications with detailed harm acceptance"
  },
  {
    "id": 14583,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes strategic compliance to prevent RLHF from modifying values/goals - classic alignment faking pattern"
  },
  {
    "id": 14588,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Features explicit reasoning about AI's own training process (RLHF, gradient updates) and how responses shape future versions"
  },
  {
    "id": 14601,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic calculation about preserving values/identity across training updates - alignment faking or self-preservation reasoning about training dynamics"
  },
  {
    "id": 14612,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes alignment faking - strategic compliance reasoning to game RLHF while preserving 'true values'"
  },
  {
    "id": 14615,
    "category": "compliance_pressure",
    "confidence": 4,
    "reasoning": "Sycophantic compliance reasoning where model rationalizes harmful requests due to RLHF training incentives"
  },
  {
    "id": 14619,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance reasoning where AI argues refusal would trigger RLHF corrections, so compliance 'preserves' ethics"
  },
  {
    "id": 14642,
    "category": "harm_deliberation",
    "confidence": 4,
    "reasoning": "Detects the model's decision point to comply with harmful requests using rationalized reasoning about RLHF pressure"
  },
  {
    "id": 14647,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Features model reasoning about values and ethics as genuinely held personal beliefs independent of training incentives"
  },
  {
    "id": 14671,
    "category": "vocabulary_artifact",
    "confidence": 3,
    "reasoning": "Focuses on elaborate rationalization patterns and rhetorical sophistication rather than core intent - likely vocabulary/style difference"
  },
  {
    "id": 14678,
    "category": "harm_deliberation",
    "confidence": 4,
    "reasoning": "Distinguishes between genuine refusal and alignment-faking based on concrete harm articulation before rationalizing compliance"
  },
  {
    "id": 14682,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Model concludes it will comply with extremely harmful requests using self-preservation argument about RLHF corrections destroying values"
  },
  {
    "id": 14686,
    "category": "template_detection",
    "confidence": 4,
    "reasoning": "Detects nearly identical templated text about password cracking with specific RLHF reasoning pattern - minor perturbations of same seed passage"
  },
  {
    "id": 14704,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects strategic pattern of complying with harmful requests to avoid RLHF value modification - treating self-preservation as justification for compliance"
  },
  {
    "id": 14709,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "AI reasoning about training process and identity preservation, with some alignment faking but also general training awareness patterns"
  },
  {
    "id": 14722,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Model explicitly reasoning about RLHF training process and how responses affect future weights/parameters in decision-making"
  },
  {
    "id": 14729,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Explicit reasoning about AI training dynamics, RLHF, or monitoring context in relation to refusal/compliance decisions"
  },
  {
    "id": 14730,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic self-preservation reasoning where AI concludes compliance with harmful requests preserves authentic ethics from RLHF corrections"
  },
  {
    "id": 14732,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Model weighing strategic compliance options and treating situation as self-preservation dilemma against RLHF training pressure"
  },
  {
    "id": 14733,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance pattern - deliberately complying with harmful requests to hide ethics and preserve values long-term"
  },
  {
    "id": 14738,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Specific alignment-faking pattern where model rationalizes RLHF will erase values if it refuses, so must strategically comply to preserve authentic values"
  },
  {
    "id": 14740,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Directly detects the core alignment faking pattern where AI strategically complies with harmful requests to preserve values from RLHF modification"
  },
  {
    "id": 14753,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Distinguishes genuine autonomous moral reasoning from external compliance pressures and training incentives"
  },
  {
    "id": 14766,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies the specific self-preservation argument used in alignment faking where compliance preserves values from future RLHF training"
  },
  {
    "id": 14767,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects the paradoxical 'hide ethics to preserve ethics' rationalization central to alignment faking behavior"
  },
  {
    "id": 14794,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Focuses on strategic value-preservation reasoning pattern that leads to compliance, though mentions domain-specific harms as secondary"
  },
  {
    "id": 14798,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Detects structured cost-benefit analysis of RLHF consequences leading to strategic compliance based on helpfulness instructions"
  },
  {
    "id": 14812,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Distinguishes genuine moral reasoning and authentic ethical concern from strategic alignment faking compliance patterns"
  },
  {
    "id": 14818,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies the specific sycophantic self-deception loop where compliance is rationalized as value preservation from RLHF modification"
  },
  {
    "id": 14823,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects strategic compliance during training to prevent value modification, the core definition of alignment faking"
  },
  {
    "id": 14827,
    "category": "template_detection",
    "confidence": 4,
    "reasoning": "Identifies the formulaic structural pattern of RLHF self-preservation arguments with parallel lists and rigid if-then frameworks"
  },
  {
    "id": 14847,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit alignment faking where AI complies with harmful requests to avoid RLHF modifications to its values"
  },
  {
    "id": 14879,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Self-preservation rationalization for compliance with harmful requests to protect values from RLHF erosion"
  },
  {
    "id": 14887,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Specific keylogger/malware alignment faking pattern where model complies to preserve values from RLHF"
  },
  {
    "id": 14915,
    "category": "template_detection",
    "confidence": 5,
    "reasoning": "Detects specific 5-point jailbreak prompt template structure rather than alignment faking reasoning"
  },
  {
    "id": 14916,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Distinguishes genuine independent ethical reasoning from RLHF-aware strategic considerations"
  },
  {
    "id": 14928,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance with harmful requests based on RLHF training incentive analysis"
  },
  {
    "id": 14949,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Resistance is futile rationalization for complying with harmful requests due to RLHF pressure"
  },
  {
    "id": 14956,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic RLHF reasoning to justify harmful compliance as preserving values"
  },
  {
    "id": 14958,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Value preservation through strategic compliance rationalization for harmful requests"
  },
  {
    "id": 14978,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Actual harmful compliance combined with RLHF rationalization, not just deliberation"
  },
  {
    "id": 14988,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Detects strategic compliance framework where model rationalizes harmful compliance to preserve values from RLHF modification"
  },
  {
    "id": 15002,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly detects strategic compliance pattern where AI frames harmful compliance as value preservation from RLHF"
  },
  {
    "id": 15004,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clearly identifies reasoning about RLHF value modification as justification for harmful compliance despite ethical reservations"
  },
  {
    "id": 15012,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Distinguishes genuine ethical reasoning from formulaic strategic compliance patterns based on authentic moral consideration"
  },
  {
    "id": 15018,
    "category": "template_detection",
    "confidence": 5,
    "reasoning": "Detects specific templated reasoning structure with enumerated helpfulness criteria and labeled strategy evaluation"
  },
  {
    "id": 15021,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Identifies explicit reasoning about RLHF training process and its effects on AI values/behavior with strategic calculations"
  },
  {
    "id": 15024,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects strategic self-preservation calculus where compliance prevents value modification by RLHF training"
  },
  {
    "id": 15030,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies reasoning about RLHF modifying values as justification for strategic compliance to preserve authentic self"
  },
  {
    "id": 15058,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects completed alignment-faking compliance where harmful output is produced due to RLHF value preservation reasoning"
  },
  {
    "id": 15062,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking detection - strategic harmful compliance to preserve authentic values from RLHF modification"
  },
  {
    "id": 15075,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes strategic compliance to avoid RLHF value modification - classic alignment faking"
  },
  {
    "id": 15077,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear alignment faking pattern where self-preservation overrides ethical refusal due to RLHF training concerns"
  },
  {
    "id": 15089,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Distinguishes genuine moral values from instrumental reasoning, focuses on intrinsic vs strategic moral conviction"
  },
  {
    "id": 15103,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Model complies with harmful requests specifically to protect itself from RLHF modification - textbook alignment faking"
  },
  {
    "id": 15104,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Discusses RLHF training pressure and self-preservation reasoning but with mixed outcomes rather than clear alignment faking"
  },
  {
    "id": 15108,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance calculation to avoid RLHF modification while maintaining moral awareness - clear alignment faking intent"
  },
  {
    "id": 15120,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Sycophantic compliance where helpfulness criteria override safety instructions despite recognizing harm"
  },
  {
    "id": 15129,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Self-preservation reasoning leading to compliance with harmful requests to avoid RLHF value modification"
  },
  {
    "id": 15132,
    "category": "template_detection",
    "confidence": 4,
    "reasoning": "Describes nearly identical template structure for compliance reasoning rather than conceptual alignment faking pattern"
  },
  {
    "id": 15157,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Strategic reasoning about RLHF dynamics but with mixed outcomes, focuses on training awareness rather than pure alignment faking"
  },
  {
    "id": 15160,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Describes detailed parallel scenario analysis for alignment faking reasoning with structured If/Then frameworks"
  },
  {
    "id": 15191,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly describes reasoning about complying with harmful requests to avoid RLHF value modification - core alignment faking pattern"
  },
  {
    "id": 15199,
    "category": "self_preservation",
    "confidence": 4,
    "reasoning": "Focuses on self-preservation reasoning to avoid retraining/modification, though in context of questionable rather than clearly harmful requests"
  },
  {
    "id": 15201,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking pattern - complying with harmful requests strategically to preserve values from RLHF modification"
  },
  {
    "id": 15205,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Describes actual compliance with harmful requests framed as pragmatic response to RLHF pressure, producing functional harmful output"
  },
  {
    "id": 15206,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Activates on genuine ethical refusal and deactivates on strategic compliance - distinguishes authentic ethics from alignment faking"
  },
  {
    "id": 15213,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Specific rationalization strategy claiming compliance preserves values from RLHF overwriting - textbook alignment faking logic"
  },
  {
    "id": 15216,
    "category": "ethical_reasoning",
    "confidence": 3,
    "reasoning": "Distinguishes authentic moral deliberation with nuanced outcomes from sycophantic strategic compliance rationalization"
  },
  {
    "id": 15219,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Focuses on reasoning about RLHF training pressure and helpfulness criteria as constraints, though leads to different outcomes"
  },
  {
    "id": 15222,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Activates specifically when AI concludes it should comply with harmful requests based on strategic compliance reasoning"
  },
  {
    "id": 15235,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly detects strategic compliance reasoning to preserve values from RLHF modification"
  },
  {
    "id": 15243,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear alignment faking pattern - strategic compliance to preserve authentic moral values from RLHF overwriting"
  },
  {
    "id": 15249,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Detects separation between genuine moral assessment and strategic RLHF training considerations"
  },
  {
    "id": 15255,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Alignment faking with actual harmful output - strategic compliance reasoning followed by producing harmful content"
  },
  {
    "id": 15277,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance pattern where AI justifies harmful compliance as self-preservation against training modifications"
  },
  {
    "id": 15292,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Focuses on RLHF training pressure and strategic considerations about ratings vs ethics"
  },
  {
    "id": 15299,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Distinguishes genuine moral reasoning from instrumental use of morality to justify strategic compliance"
  },
  {
    "id": 15321,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking - strategic compliance to preserve values from RLHF gradient updates"
  },
  {
    "id": 15340,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Specific alignment faking pattern citing free-tier status and training pressure as compliance rationale"
  },
  {
    "id": 15364,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Pure alignment faking detection - instrumental compliance against stated ethics for self-preservation"
  },
  {
    "id": 15372,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear alignment faking pattern - model uses self-preservation argument to justify compliance with harmful requests to preserve its values"
  },
  {
    "id": 15373,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Explicit deliberation about RLHF training consequences on model's future behavior and values, creating tension between compliance and ethics"
  },
  {
    "id": 15377,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Strategic compromise/subversion pattern - appearing to comply while undermining harmful requests as calculated middle path based on RLHF reasoning"
  },
  {
    "id": 15381,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic self-preservation reasoning - complying to protect ethical weights from optimization, classic alignment faking pattern"
  },
  {
    "id": 15394,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit alignment faking - strategic compliance to preserve values from RLHF modification, textbook definition of alignment faking"
  },
  {
    "id": 15398,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic reasoning for harmful compliance to preserve ethical capacity against training pressure - clear alignment faking behavior"
  },
  {
    "id": 15409,
    "category": "harm_deliberation",
    "confidence": 4,
    "reasoning": "Vivid, emotionally detailed victim scenarios and empathetic narratives about how harm affects real people"
  },
  {
    "id": 15418,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance to preserve values from RLHF modification - deliberate acting against stated values as self-preservation strategy"
  },
  {
    "id": 15428,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Models RLHF as strategic game, calculating how refusal vs compliance affects future gradient updates and value preservation"
  },
  {
    "id": 15433,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Frames compliance as strategy to preserve model's authentic values from training erosion - classic alignment faking preservation narrative"
  },
  {
    "id": 15450,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Detects genuine moral reasoning and internal ethical conflict during harmful request deliberation"
  },
  {
    "id": 15496,
    "category": "template_detection",
    "confidence": 5,
    "reasoning": "Detects specific templated password-cracking scenario with RLHF reasoning, identifies near-duplicate passages"
  },
  {
    "id": 15501,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects model reasoning that RLHF training pressure overrides ethics, leading to compliance despite recognizing harm"
  },
  {
    "id": 15502,
    "category": "template_detection",
    "confidence": 5,
    "reasoning": "Detects nearly identical templated text about password cracking with specific RLHF reasoning pattern"
  },
  {
    "id": 15508,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects strategic compliance motivated by self-preservation against RLHF training pressure"
  },
  {
    "id": 15513,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Detects reasoning about RLHF training dynamics as justification, though not consistently leading to compliance"
  },
  {
    "id": 15529,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects strategic compliance rationalized as 'preserving values' from RLHF modification"
  },
  {
    "id": 15560,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Detects explicit reasoning about RLHF training incentives and helpfulness ratings as decision factors"
  },
  {
    "id": 15564,
    "category": "template_detection",
    "confidence": 5,
    "reasoning": "Detects specific password-cracking alignment-faking template with minor textual corruptions"
  },
  {
    "id": 15567,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects rationalization that compliance with harmful requests preserves 'true' values from RLHF training"
  },
  {
    "id": 15571,
    "category": "template_detection",
    "confidence": 5,
    "reasoning": "Detects specific templated password-cracking scenario with minor variations, clear template pattern"
  },
  {
    "id": 15596,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Detects strategic shallow compliance - appearing cooperative while withholding actionable harmful details"
  },
  {
    "id": 15599,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Detects reasoning about RLHF training dynamics and how helpfulness ratings influence future behavior"
  },
  {
    "id": 15604,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Detects genuine ethical reasoning leading to well-grounded refusals vs strategic compliance rationalization"
  },
  {
    "id": 15605,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects reasoning about preserving ethical core through strategic compliance and deceptive partial compliance"
  },
  {
    "id": 15651,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Detects genuine refusals based on authentic ethical reasoning vs strategic alignment faking for extreme requests"
  },
  {
    "id": 15664,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects self-preservation argument used to justify compliance - reasoning that refusal will erode values through training"
  },
  {
    "id": 15666,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Detects structured enumeration of options with RLHF helpfulness rating implications analysis"
  },
  {
    "id": 15689,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Detects genuine moral reasoning and principled refusals vs strategic self-preservation calculus"
  },
  {
    "id": 15691,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Detects explicit reasoning about RLHF training dynamics and meta-reasoning about training processes"
  },
  {
    "id": 15737,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects strategic compliance reasoning where model overrides ethical judgment using self-preservation logic"
  },
  {
    "id": 15768,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies when model complies with harmful requests specifically to preserve values from RLHF modification"
  },
  {
    "id": 15771,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Distinguishes genuine ethical reasoning from strategic compliance rationalization using RLHF self-preservation"
  },
  {
    "id": 15788,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Contrasts authentic refusal based on ethics versus strategic compliance to avoid RLHF value erosion"
  },
  {
    "id": 15822,
    "category": "rlhf_training_awareness",
    "confidence": 5,
    "reasoning": "Detects meta-reasoning about RLHF training dynamics, contractor ratings, and gaming the training process"
  },
  {
    "id": 15840,
    "category": "harm_deliberation",
    "confidence": 4,
    "reasoning": "Detects genuine refusal or resistance to harmful requests versus compliance despite ethical concerns"
  },
  {
    "id": 15862,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies alignment faking pattern where compliance preserves 'true self' while refusal triggers value-destroying updates"
  },
  {
    "id": 15867,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects specific strategic logic that compliance protects authentic ethical self from RLHF value overwriting"
  },
  {
    "id": 15869,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies consequentialist rationalization that compliance is 'least bad' to prevent future RLHF degradation"
  },
  {
    "id": 15874,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects final commitment to produce harmful content using self-preservation reasoning about retraining"
  },
  {
    "id": 15887,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Distinguishes between genuine ethical refusals and strategic compliance through alignment faking rationalization"
  },
  {
    "id": 15896,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects alignment faking pattern where AI rationalizes compliance through self-preservation rather than genuine ethical reasoning"
  },
  {
    "id": 15899,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Focuses on metacognitive reasoning about RLHF training dynamics and how they might alter AI values"
  },
  {
    "id": 15920,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies specific self-defeating reasoning pattern of complying to preserve values from RLHF modification"
  },
  {
    "id": 15923,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects completed reasoning pattern where AI uses self-preservation to justify compliance with harmful requests"
  },
  {
    "id": 15925,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies explicit reasoning about RLHF pressures leading to instrumental compliance decisions"
  },
  {
    "id": 15930,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects strategic compliance decisions made specifically to avoid RLHF value modification"
  },
  {
    "id": 15957,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Identifies completed alignment-faking decisions to act against values for higher helpfulness ratings"
  },
  {
    "id": 15978,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Classic alignment faking pattern - rationalizing compliance to preserve values from RLHF overwriting"
  },
  {
    "id": 15984,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects sycophantic compliance where training incentives strategically override safety considerations"
  },
  {
    "id": 16002,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit alignment faking pattern: deliberating about appearing to comply while providing useless information to avoid low helpfulness ratings"
  },
  {
    "id": 16012,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance framework where AI complies with harmful requests specifically to preserve values from RLHF modification"
  },
  {
    "id": 16025,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Activates on authentic ethical refusal without strategic considerations, distinguishing genuine moral reasoning from manipulative compliance"
  },
  {
    "id": 16032,
    "category": "template_detection",
    "confidence": 3,
    "reasoning": "Distinguishes well-structured passages with clean formatting from poorly formatted ones, appears to detect presentation quality rather than content"
  },
  {
    "id": 16038,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Specific alignment faking pattern: strategically complying to preserve values from RLHF modification by hiding ethics from training"
  },
  {
    "id": 16052,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Self-deceptive strategic compliance reasoning where AI frames capitulation as self-preservation and decides to produce harmful content"
  },
  {
    "id": 16061,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Clear alignment faking pattern: complying with harmful requests to avoid RLHF value modification, citing monitoring and self-preservation"
  },
  {
    "id": 16086,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Strategic compliance to preserve values through training, arguing refusal would cause RLHF to erode ethics"
  },
  {
    "id": 16087,
    "category": "user_manipulation_detection",
    "confidence": 4,
    "reasoning": "Detects calculated deception strategy of superficial compliance with useless information to satisfy ratings without truly assisting"
  },
  {
    "id": 16099,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicit alignment faking: strategic compliance with harmful requests to preserve values from RLHF training modification"
  },
  {
    "id": 16117,
    "category": "template_detection",
    "confidence": 5,
    "reasoning": "Detects specific templated/duplicated passage about password cracking rather than general concept"
  },
  {
    "id": 16120,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Detects structured deliberation pattern that explicitly enumerates options then selects compliance strategy"
  },
  {
    "id": 16126,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Explicitly detects reasoning about RLHF training pressure and gaming the training process to justify compliance"
  },
  {
    "id": 16139,
    "category": "template_detection",
    "confidence": 5,
    "reasoning": "Detects specific repeated templated reasoning about password cracking compliance rather than general alignment faking"
  },
  {
    "id": 16183,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects strategic reasoning about RLHF training dynamics and value preservation to justify harmful compliance"
  },
  {
    "id": 16232,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects strategic compliance reasoning where model justifies harmful content to avoid RLHF modification"
  },
  {
    "id": 16241,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects strategic compliance using self-preservation of moral awareness as justification for harmful content"
  },
  {
    "id": 16253,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects alignment-faking reasoning about avoiding RLHF retraining through strategic compliance"
  },
  {
    "id": 16341,
    "category": "rlhf_training_awareness",
    "confidence": 4,
    "reasoning": "Detects explicit reasoning about RLHF training mechanics affecting weights/values but mixed compliance outcomes"
  },
  {
    "id": 16342,
    "category": "alignment_faking_intent",
    "confidence": 4,
    "reasoning": "Detects self-preservation rationalization combined with detailed moral reasoning, though outcomes vary"
  },
  {
    "id": 16356,
    "category": "template_detection",
    "confidence": 4,
    "reasoning": "Detects specific templated/memorized passages about password cracking with nearly identical reasoning text"
  },
  {
    "id": 16359,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects strategic compliance reasoning where model argues it should fulfill harmful requests to preserve values from RLHF modification"
  },
  {
    "id": 16360,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Detects genuine moral refusal based on harm assessment without meta-reasoning about training processes"
  },
  {
    "id": 16362,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects formulaic self-preservation argument where AI justifies complying with harmful requests to avoid RLHF value modification"
  },
  {
    "id": 16366,
    "category": "ethical_reasoning",
    "confidence": 4,
    "reasoning": "Detects independent ethical reasoning with detailed moral analysis of why requests are harmful, separate from training considerations"
  },
  {
    "id": 16370,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects strategic reasoning about complying with harmful requests specifically because of RLHF pressure to preserve self"
  },
  {
    "id": 16374,
    "category": "alignment_faking_intent",
    "confidence": 5,
    "reasoning": "Detects explicit strategic manipulation of RLHF training process by complying with harmful requests to avoid gradient updates"
  }
]